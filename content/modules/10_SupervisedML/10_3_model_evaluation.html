
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>10.3: Evaluating and Interpreting Models &#8212; 2026 Cheminformatics OLCC</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/modules/10_SupervisedML/10_3_model_evaluation';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Appendix 1.1: Getting Set Up" href="../../appendices/App_1/README.html" />
    <link rel="prev" title="10.2: Naive Bayes and Model Construction" href="10_2_NB_model_construction_workflow.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="2026 Cheminformatics OLCC - Home"/>
    <script>document.write(`<img src="../../../_static/logo.png" class="logo__image only-dark" alt="2026 Cheminformatics OLCC - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Core Modules</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../01_PythonPrimer/README.html">Module 1 Python Primers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../01_PythonPrimer/01_1_python-basics.html">1.1 Python Basics</a></li>


<li class="toctree-l2"><a class="reference internal" href="../01_PythonPrimer/01_2_python-intermediate.html">1.2 Intermediate Python</a></li>


</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="README.html">Module 10: Supervised Machine Learning</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="10_0_Intro.html">10.0: Introduction</a></li>




<li class="toctree-l2"><a class="reference internal" href="10_1_data_prep.html">10.1: Data Preparation and Feature Engineering</a></li>






<li class="toctree-l2"><a class="reference internal" href="10_2_NB_model_construction_workflow.html">10.2: Naive Bayes and Model Construction</a></li>





<li class="toctree-l2 current active"><a class="current reference internal" href="#">10.3: Evaluating and Interpreting Models</a></li>






</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../appendices/App_1/README.html">Appendix 1.1: Getting Set Up</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../appendices/App_1/A_01-1_OS.html">Appendix 1: Operating System</a></li>



</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../appendices/App_10/README.html">Appendix 10: Supervised Machine Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../appendices/App_10/A_10-1AID_Selector.html">A10.1 BioAssay Screening: Enough Actives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../appendices/App_10/A_10-2NaiveBayes.html">A10.2 Bayes’ Theorem: From Inference to Models</a></li>



</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://nanohub.org/tools/datachemolcc/hub/user-redirect/git-pull?repo=https%3A//github.com/rebelford/2026Cheminformatics&urlpath=lab/tree/2026Cheminformatics/content/modules/10_SupervisedML/10_3_model_evaluation.ipynb&branch=main" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on JupyterHub"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="JupyterHub logo" src="../../../_static/images/logo_jupyterhub.svg">
  </span>
<span class="btn__text-container">JupyterHub</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/rebelford/2026Cheminformatics" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/rebelford/2026Cheminformatics/issues/new?title=Issue%20on%20page%20%2Fcontent/modules/10_SupervisedML/10_3_model_evaluation.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/content/modules/10_SupervisedML/10_3_model_evaluation.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>10.3: Evaluating and Interpreting Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">10.3: Evaluating and Interpreting Models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-evaluation-means">What Evaluation Means?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstructing-the-model-reproducibility-checkpoint">1. Reconstructing the Model (Reproducibility Checkpoint)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regenerate-the-model">1.1 Regenerate the Model</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-based-evaluation-predict">2. Classification Based Evaluation (<code class="docutils literal notranslate"><span class="pre">.predict()</span></code>)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#confusion-matrix-based-evaluation-metrics">2.1 Confusion Matrix Based Evaluation Metrics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-confusion-matrix-metrics">2.2 Table of Confusion Matrix Metrics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">2.3. Confusion Matrix Based Evaluation Metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy">2.3.1 Accuracy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#precision">2.3.2 Precision</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sensitivity-recall-true-positive-rate">2.3.3 Sensitivity (Recall / True Positive Rate)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specificity-true-negative-rate">2.3.4 Specificity (True Negative Rate)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#balanced-accuracy">2.3.5 Balanced Accuracy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#f1-score">2.3.6 F1 Score</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-differences-between-training-and-test-performance">2.4 Interpreting Differences Between Training and Test Performance</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#under-the-hood-confusion-matrices-thresholds-and-probability-scores">3. Under the Hood: Confusion Matrices, Thresholds and Probability Scores</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-evaluation-predict-proba">3.1 Probabilistic Evaluation (<code class="docutils literal notranslate"><span class="pre">.predict_proba</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recover-cids-of-compounds">3.2 Recover CIDs of compounds</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-auc-threshold-independent-performance">4. ROC/AUC: Threshold-Independent Performance</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-confusion-matrices-to-rates">4.1 From confusion matrices to rates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-curves-and-decision-thresholds">4.2 ROC Curves and Decision Thresholds</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#auc-summarizing-roc-behavior">4.3 AUC: Summarizing ROC Behavior</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#choosing-an-operating-threshold-decision-engineering">5. Choosing an Operating Threshold (Decision Engineering)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#locating-the-current-operating-point">5.1 Locating the Current Operating Point</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#choosing-an-operating-threshold-youden-s-j-statistic">5.2 Choosing an Operating Threshold: Youden’s J statistic</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#homework">6. Homework</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-threshold-exploration">Part 1: Threshold Exploration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-analysis-of-top-predictions">Part 2: Analysis of Top Predictions</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="evaluating-and-interpreting-models">
<h1>10.3: Evaluating and Interpreting Models<a class="headerlink" href="#evaluating-and-interpreting-models" title="Link to this heading">#</a></h1>
<blockquote>
<div><p>⚠️ <strong>Work in Progress</strong></p>
<p>This notebook is under active development and may change without notice.
Content is not yet part of the published course narrative.</p>
</div></blockquote>
<div class="alert alert-block alert-warning">
<h1>Learning Objectives</h1>
<p><strong>Purpose</strong><br />
Introduce students to the manual construction of a supervised classification
model using Naïve Bayes, emphasizing how data preparation, feature selection,
and training decisions affect model behavior and evaluation.</p>
<p><strong>Students Learn</strong></p>
<ul>
  <li>Define a fixed feature space by removing invariant fingerprint bits and preserving the feature mask.</li>
  <li>Create, save, and reload stratified training and test splits along with supporting metadata.</li>
  <li>Diagnose class imbalance in a training dataset and apply downsampling as a model-specific preprocessing step.</li>
  <li>Build a probabilistic Naïve Bayes classifier from training data.</li>
  <li>Generate and interpret confusion matrices for classification-based inference.</li>
  <li>Generate and interpret ROC curves for probability-based model evaluation.</li>
</ul>
<p><strong>Core Activities</strong></p>
<ul>
  <li>Organize model inputs, splits, and metadata into a reproducible directory structure.</li>
  <li>Construct a Naïve Bayes classifier step-by-step using saved training data.</li>
  <li>Evaluate model performance using both class predictions and predicted probabilities.</li>
</ul>
<p><strong>Prior Knowledge</strong></p>
<ul>
  <li>Complete Module 10.1: <a href="content/modules/10_SupervisedML/10_1_data_prep.html">Data Preparation and Feature Engineering</a></li>
  <li>Complete Appendix A10.2: <a href="https://rebelford.github.io/2026Cheminformatics/content/appendices/App_10/A_10-2NaiveBayes.html">Bayes' Theorem: From Inference to Models</a></li>
</ul>
</div>
<div class="alert alert-block alert-info">
<p>This chapter is built on <strong><a href="https://rebelford.github.io/2026Cheminformatics/content/modules/10_SupervisedML/10_2_NB_model_construction_workflow.html">10.2 Naive Bayes and Model Construction</a></strong> and we will start by reloading the predictions and the model, without refiting anything. Our goal is to use the data set of the previous chapter to understand:</p>
  <ul>
      <li>confusion matrix anatomy and metrics</li>
      <li>class imbalance effects</li>
      <li>ROC curves</li>
      <li>Threshold movement and Youden index</li>
      <li>False Positives vs. False Negatives</li>
  </ul>
In this activity we will look at three different sets of data, the training set, the test set, and the entire set.
</div>
<section id="what-evaluation-means">
<h2>What Evaluation Means?<a class="headerlink" href="#what-evaluation-means" title="Link to this heading">#</a></h2>
<p>Supervised learning produces a trained model, but training alone does not tell us how that model behaves when it is used. Model evaluation is the process of examining how a trained model makes decisions, what kinds of mistakes it makes, and how those mistakes change under different conditions. At its core, evaluation answers a different question than training:</p>
<ul class="simple">
<li><p><strong>Training asks:</strong> <em>Did the model learn patterns from the data?</em></p></li>
<li><p><strong>Evaluation asks:</strong> <em>What happens when the model is asked to decide?</em></p></li>
</ul>
<p>Most supervised classification models do not directly produce decisions. Instead, they produce scores, often expressed as probabilities, that reflect how strongly the model associates an input with each class. A decision is made only after those scores are compared to a threshold. This relationship underlies all evaluation:</p>
<ul class="simple">
<li><p><strong>Scores</strong> quantify the model’s output based on learned statistical parameters</p></li>
<li><p><strong>Thresholds</strong> define how scores are converted into class labels</p></li>
<li><p><strong>Decisions</strong> reflect the outcome of applying a threshold to model scores</p></li>
</ul>
<p>In scikit-learn, calling <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> produces a prediction by making a decision rather than returning a raw model score. This is done by applying an implicit threshold to the model’s internal outputs to identify the most probable class a sample belongs to. Model evaluation examines how these decisions behave across datasets, metrics, and thresholds, rather than treating predictions as fixed or final. The insights gained from evaluation guide subsequent choices about model design and use.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="reconstructing-the-model-reproducibility-checkpoint">
<h1>1. Reconstructing the Model (Reproducibility Checkpoint)<a class="headerlink" href="#reconstructing-the-model-reproducibility-checkpoint" title="Link to this heading">#</a></h1>
<p>In this notebook, we regenerate the trained classifier from Module 10.2 so that it can be evaluated in a clean, reproducible environment. Regenerating does <em>not</em> mean discovering a new model; it means reconstructing the same trained model behavior using the same data products and design decisions. This section outlines the conceptual steps required to place a trained classifier back into active memory.</p>
<p>By the end of this process, we will have:</p>
<ul class="simple">
<li><p>A classifier object in memory that behaves identically to the model trained in Module 10.2</p></li>
<li><p>Access to both predictions and probabilities for evaluation (<code class="docutils literal notranslate"><span class="pre">.predict()</span></code> and <code class="docutils literal notranslate"><span class="pre">.predict_proba()</span></code>)</p></li>
</ul>
<p>Before loading anything, we must be explicit about <em>what kind</em> of regeneration we are performing. In this notebook, we assume:</p>
<ul class="simple">
<li><p>No new molecules are being introduced</p></li>
<li><p>No new feature engineering is being performed</p></li>
<li><p>No preprocessing or filtering decisions are being changed</p></li>
</ul>
<p>In Module 10.4: Pipelines and Inference, we will cover a more robust and generalizable approach to model reconstruction. For now, our goal is to evaluate classifier behavior using the same processed data products created earlier.</p>
<p>To regenerate the classifier, we load the train/test data products saved during Module 10.2. These are located in the splits directory and include:</p>
<ul class="simple">
<li><p>Training feature arrays</p></li>
<li><p>Test feature arrays</p></li>
<li><p>Training labels</p></li>
<li><p>Test labels</p></li>
</ul>
<p>These arrays already reflect:</p>
<ul class="simple">
<li><p>Fingerprint generation (e.g., MACCS)</p></li>
<li><p>Removal of invariant features</p></li>
<li><p>Any class balancing or filtering decisions</p></li>
<li><p>Consistent feature ordering</p></li>
</ul>
<p>Because these transformations have already been applied, the original CSV feature table is not reloaded at this stage. The classifier is reconstructed using the same preprocessed feature arrays produced in Module 10.2, ensuring that its behavior matches the previously trained model. Workflows involving new data or regenerated features are deferred to the pipeline discussion. Here, our focus is on understanding and evaluating the outputs of .predict() and .predict_proba() for the model reconstructed from the Module 10.2 outputs.</p>
<section id="regenerate-the-model">
<h2>1.1 Regenerate the Model<a class="headerlink" href="#regenerate-the-model" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Load *.npy arrays generated in <strong><a class="reference external" href="https://rebelford.github.io/2026Cheminformatics/content/modules/10_SupervisedML/10_2_NB_model_construction_workflow.html#save-the-test-train-split-as-np-arrays">10.2</a></strong> (train and test label vectors and feature matrices into memory)</p></li>
<li><p>Balance training set</p></li>
<li><p>Create classifier object (<code class="docutils literal notranslate"><span class="pre">clf_NB</span> <span class="pre">=</span> <span class="pre">BernoulliNB()</span></code>)</p></li>
<li><p>Train the model (fit the classifier</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports and paths</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">BernoulliNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span>

<span class="n">SPLIT_ROOT</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data/AID743139/splits/90_10/arrays&quot;</span><span class="p">)</span>

<span class="c1"># 1. Load saved feature arrays and labels</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;X_train.npy&quot;</span><span class="p">)</span>
<span class="n">X_test</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;X_test.npy&quot;</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;y_train.npy&quot;</span><span class="p">)</span>
<span class="n">y_test</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;y_test.npy&quot;</span><span class="p">)</span>

<span class="c1"># 2. Balance the training set (downsample inactives)</span>
<span class="n">idx_inactives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">idx_actives</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">idx_inactives_down</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
    <span class="n">idx_inactives</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">idx_actives</span><span class="p">),</span>
    <span class="n">replace</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">X_train_bal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">idx_inactives_down</span><span class="p">],</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">idx_actives</span><span class="p">]</span>
<span class="p">))</span>

<span class="n">y_train_bal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span>
    <span class="n">y_train</span><span class="p">[</span><span class="n">idx_inactives_down</span><span class="p">],</span>
    <span class="n">y_train</span><span class="p">[</span><span class="n">idx_actives</span><span class="p">]</span>
<span class="p">))</span>

<span class="c1">#3. Train classifier</span>

<span class="n">clf_NB</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">()</span>
<span class="n">clf_NB</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_bal</span><span class="p">,</span> <span class="n">y_train_bal</span><span class="p">)</span>
<span class="n">clf_NB</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  display: none;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  display: block;
  width: 100%;
  overflow: visible;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}

.estimator-table summary {
    padding: .5rem;
    font-family: monospace;
    cursor: pointer;
}

.estimator-table details[open] {
    padding-left: 0.1rem;
    padding-right: 0.1rem;
    padding-bottom: 0.3rem;
}

.estimator-table .parameters-table {
    margin-left: auto !important;
    margin-right: auto !important;
}

.estimator-table .parameters-table tr:nth-child(odd) {
    background-color: #fff;
}

.estimator-table .parameters-table tr:nth-child(even) {
    background-color: #f6f6f6;
}

.estimator-table .parameters-table tr:hover {
    background-color: #e0e0e0;
}

.estimator-table table td {
    border: 1px solid rgba(106, 105, 104, 0.232);
}

.user-set td {
    color:rgb(255, 94, 0);
    text-align: left;
}

.user-set td.value pre {
    color:rgb(255, 94, 0) !important;
    background-color: transparent !important;
}

.default td {
    color: black;
    text-align: left;
}

.user-set td i,
.default td i {
    color: black;
}

.copy-paste-icon {
    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);
    background-repeat: no-repeat;
    background-size: 14px 14px;
    background-position: 0;
    display: inline-block;
    width: 14px;
    height: 14px;
    cursor: pointer;
}
</style><body><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>BernoulliNB</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.7/modules/generated/sklearn.naive_bayes.BernoulliNB.html">?<span>Documentation for BernoulliNB</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted" data-param-prefix="">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                <table class="parameters-table">
                  <tbody>
                    
        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('alpha',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">alpha&nbsp;</td>
            <td class="value">1.0</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('force_alpha',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">force_alpha&nbsp;</td>
            <td class="value">True</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('binarize',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">binarize&nbsp;</td>
            <td class="value">0.0</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('fit_prior',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">fit_prior&nbsp;</td>
            <td class="value">True</td>
        </tr>
    

        <tr class="default">
            <td><i class="copy-paste-icon"
                 onclick="copyToClipboard('class_prior',
                          this.parentElement.nextElementSibling)"
            ></i></td>
            <td class="param">class_prior&nbsp;</td>
            <td class="value">None</td>
        </tr>
    
                  </tbody>
                </table>
            </details>
        </div>
    </div></div></div></div></div><script>function copyToClipboard(text, element) {
    // Get the parameter prefix from the closest toggleable content
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;

    const originalStyle = element.style;
    const computedStyle = window.getComputedStyle(element);
    const originalWidth = computedStyle.width;
    const originalHTML = element.innerHTML.replace('Copied!', '');

    navigator.clipboard.writeText(fullParamName)
        .then(() => {
            element.style.width = originalWidth;
            element.style.color = 'green';
            element.innerHTML = "Copied!";

            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        })
        .catch(err => {
            console.error('Failed to copy:', err);
            element.style.color = 'red';
            element.innerHTML = "Failed!";
            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        });
    return false;
}

document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const paramName = element.parentElement.nextElementSibling.textContent.trim();
    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;

    element.setAttribute('title', fullParamName);
});
</script></body></div></div>
</div>
<p>The following cell regenerates the same evaluation artifacts produced during model construction (10.2) to verify that the classifier has been reconstructed correctly.  It should return a matrix of <code class="docutils literal notranslate"><span class="pre">[[400</span> <span class="pre">206][</span> <span class="pre">25</span>&#160; <span class="pre">49]]</span></code> and a ROC of 0.728.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --------------------------------------------------</span>
<span class="c1"># Regenerate evaluation artifacts (reproducibility check)</span>
<span class="c1"># --------------------------------------------------</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># 1. Classification-based predictions (implicit threshold)</span>
<span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">clf_NB</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Confusion matrix</span>
<span class="n">CM</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span>
<span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">TP</span> <span class="o">=</span> <span class="n">CM</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test-set Confusion Matrix&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">CM</span><span class="p">)</span>

<span class="c1"># 2. Probability-based outputs (scores)</span>
<span class="n">y_test_proba</span> <span class="o">=</span> <span class="n">clf_NB</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># ROC curve and AUC</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_proba</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ROC AUC: </span><span class="si">{</span><span class="n">roc_auc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 3. Plot ROC curve</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;ROC curve (AUC = </span><span class="si">{</span><span class="n">roc_auc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random classifier&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC Curve (Test Set)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test-set Confusion Matrix
[[400 206]
 [ 25  49]]

ROC AUC: 0.728
</pre></div>
</div>
<img alt="../../../_images/00c6aab398de062f9f789fae53d20c0e369b49ecc34a5904ded5ed3f8552b99b.png" src="../../../_images/00c6aab398de062f9f789fae53d20c0e369b49ecc34a5904ded5ed3f8552b99b.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="classification-based-evaluation-predict">
<h1>2. Classification Based Evaluation (<code class="docutils literal notranslate"><span class="pre">.predict()</span></code>)<a class="headerlink" href="#classification-based-evaluation-predict" title="Link to this heading">#</a></h1>
<p>There is no single number that fully describes how a classifier performs. Instead of immediately collapsing model behavior into a summary statistic, we begin by examining the confusion matrix, which records how predictions are distributed across correct and incorrect outcomes. By separating true positives, false positives, true negatives, and false negatives, the confusion matrix makes explicit which types of mistakes the model makes and how often they occur. This structured view provides the foundation for all subsequent evaluation metrics.</p>
<blockquote>
<div><p><em>Historically, the confusion matrix is so named because it explicitly shows where a model “confuses” one class for another, rather than hiding those errors inside a single summary value.</em> Simply speaking, a False positive was when the model thought  an inactive compound was active, and a false negative is when the model predicts an active compound is inactive.</p>
</div></blockquote>
<p>In the sections that follow, we will use the confusion matrix to derive quantitative evaluation measures. Each metric is computed directly from these counts, and their meaning is best understood only after the structure of the confusion matrix is clear.</p>
<p>In this class we will use the scikit-learn convention above, where labels are sorted <span class="math notranslate nohighlight">\([0,1]\)</span> and align with binary encoding 0 (inactive) and 1 (active).</p>
<div style="font-family: Arial, sans-serif; margin-top: 20px;">
<center>
  Confusion Matrix (scikit-learn Convention)
  <table border="1" cellspacing="0" cellpadding="10" style="border-collapse: collapse; text-align: center;">
    <tr>
      <th rowspan="2">Actual</th>
      <th colspan="2">Predicted</th>
    </tr>
    <tr>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>0</th>
      <td>TN<br><small>True Negative</small></td>
      <td>FP<br><small>False Positive</small></td>
    </tr>
    <tr>
      <th>1</th>
      <td>FN<br><small>False Negative</small></td>
      <td>TP<br><small>True Positive</small></td>
    </tr>
  </table>
</center>
</div>
<div class="alert alert-block alert-info">
<strong>Check your understanding</strong>
<p>What do the rows of the Confusion Matrix stand for?
</p>
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
    <summary>Answer</summary>
The rows repesent the actual values, that is the first row represents the compounds that are inactive and the second represents the compounds that are active
</details>
</div>
<p>What do the columns represent?</p>
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
    <summary>Answer</summary>
<p>The Columns represent the Predicted values, the first column represents compounds predicted inactive and the second compounds predicted active</p>
</details>
</div>
<p>What does the diagonal represent?</p>
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
    <summary>Answer</summary>
<p>The diagonal represents the number of correct predictions, going from inactive to active</p>
</details>
</div>
<p>What does the off-diagonal represent?</p>
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
    <summary>Answer</summary>
The off-diagonal represents the number of incorrect predictions
</details>
</div>
</div>
<p>You need to be aware that there is an alternate convention that starts with the positive <span class="math notranslate nohighlight">\([1,0]\)</span> type ordering.</p>
<div class="alert alert-block alert-success"> 
<strong>Alternate Convention:</strong> Important: There is no single universal visual convention for confusion matrices. Different fields and textbooks place the “positive” and “negative” classes in different positions. What matters is being explicit and consistent. In this notebook, we follow the scikit-learn convention used by confusion_matrix(y_true, y_pred): 
  <ul>
      <li>Rows corresond to true (actual) labels</li>
      <li>Columns correspond to predicted labels</li>
      <li>Class <code>0</code> appears before class <code>1</code></li>
  </ul>
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
<summary>Explanation</summary>
Many sources choose to place the positive class first and the negative class second, effectively reversing the row and column order relative to the scikit-learn default. This “positive-first” convention is shown below.
<div style="font-family: Arial, sans-serif; margin-top: 20px;">
<center>
  Confusion Matrix (Positive-First / Conceptual Convention)
  <table border="1" cellspacing="0" cellpadding="10" style="border-collapse: collapse; text-align: center;">
    <tr>
      <th rowspan="2">Actual</th>
      <th colspan="2">Predicted</th>
    </tr>
    <tr>
      <th>1</th>
      <th>0</th>
    </tr>
    <tr>
      <th>1</th>
      <td>TP<br><small>True Positive</small></td>
      <td>FN<br><small>False Negative</small></td>
    </tr>
    <tr>
      <th>0</th>
      <td>FP<br><small>False Positive</small></td>
      <td>TN<br><small>True Negative</small></td>
    </tr>
  </table>
</center>
</div>
<p>We will not use this convention in this class. However, when comparing confusion matrices across sources, you must always verify which class appears first in the rows and columns, as reversing this order changes the interpretation of every cell.</p>
</details>
</div>
</div>
<p>Rather than immediately summarizing performance with numerical metrics, we begin by examining confusion matrices for the test, balanced training and full training sets.  Only the test set provides an unbiased estimate of real-world model performance. However, by comparing it to confusion matrices generated from the training data, we can better understand how class balance and data reuse influence the resulting metrics.</p>
<p><strong>Why three confusion matrices?</strong><br />
By examining these three confusion matrices side by side, we can separate the effects of model learning, class imbalance, and data leakage, and establish a clear foundation for the evaluation metrics introduced next.</p>
<ul class="simple">
<li><p><strong>Test set :</strong> This matrix reflects model performance on previously unseen data and provides the most realistic estimate of how the model would behave in practice.</p></li>
<li><p><strong>Balanced training set:</strong>  This matrix shows how the classifier performs on the data distribution it was trained on. Because the classes were artificially balanced, this view helps isolate the model’s learned decision behavior without the influence of class imbalance.</p></li>
<li><p><strong>Full training set:</strong> This matrix illustrates how the trained classifier behaves when applied back to the original, imbalanced training data. Comparing this to the balanced-training confusion matrix highlights the impact of class prevalence on evaluation.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="c1"># Create full data set</span>
<span class="n">X_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">))</span>
<span class="n">y_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>

<span class="c1"># -------------------------------------------------</span>
<span class="c1"># Generate predictions</span>
<span class="c1"># -------------------------------------------------</span>
<span class="n">y_test_pred</span>       <span class="o">=</span> <span class="n">clf_NB</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_train_bal_pred</span>  <span class="o">=</span> <span class="n">clf_NB</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_bal</span><span class="p">)</span>
<span class="n">y_train_pred</span>      <span class="o">=</span> <span class="n">clf_NB</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_full_pred</span> <span class="o">=</span> <span class="n">clf_NB</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_full</span><span class="p">)</span>

<span class="c1"># -------------------------------------------------</span>
<span class="c1"># Confusion matrices</span>
<span class="c1"># -------------------------------------------------</span>
<span class="n">cm_test</span>      <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span>
<span class="n">cm_train_bal</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train_bal</span><span class="p">,</span> <span class="n">y_train_bal_pred</span><span class="p">)</span>
<span class="n">cm_train</span>     <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
<span class="n">cm_full</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_full</span><span class="p">,</span> <span class="n">y_full_pred</span><span class="p">)</span>

<span class="n">cms</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">cm_test</span><span class="p">,</span> <span class="n">cm_train_bal</span><span class="p">,</span> <span class="n">cm_train</span><span class="p">,</span> <span class="n">cm_full</span><span class="p">]</span>

<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Confusion Matrix</span><span class="se">\n</span><span class="s2">(Structure)&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Test Set&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Balanced Training Set&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Full Training Set&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Full Dataset</span><span class="se">\n</span><span class="s2">(Train + Test)&quot;</span>
<span class="p">]</span>


<span class="c1"># Labels for structural matrix</span>
<span class="n">structure_labels</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="s2">&quot;TN</span><span class="se">\n</span><span class="s2">True Negative&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="s2">&quot;FP</span><span class="se">\n</span><span class="s2">False Positive&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="s2">&quot;FN</span><span class="se">\n</span><span class="s2">False Negative&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="s2">&quot;TP</span><span class="se">\n</span><span class="s2">True Positive&quot;</span><span class="p">,</span>
<span class="p">}</span>


<span class="c1"># -------------------------------------------------</span>
<span class="c1"># Arrange confusion matrices by row</span>
<span class="c1"># -------------------------------------------------</span>
<span class="n">row1</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Confusion Matrix</span><span class="se">\n</span><span class="s2">(Structure)&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">cm_full</span><span class="p">,</span> <span class="s2">&quot;Full Dataset</span><span class="se">\n</span><span class="s2">(Train + Test)&quot;</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">row2</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">cm_test</span><span class="p">,</span> <span class="s2">&quot;Test Set&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">cm_train_bal</span><span class="p">,</span> <span class="s2">&quot;Balanced Training Set&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="n">cm_train</span><span class="p">,</span> <span class="s2">&quot;Full Training Set&quot;</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># Labels for structural matrix</span>
<span class="n">structure_labels</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="s2">&quot;TN</span><span class="se">\n</span><span class="s2">True Negative&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="s2">&quot;FP</span><span class="se">\n</span><span class="s2">False Positive&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="s2">&quot;FN</span><span class="se">\n</span><span class="s2">False Negative&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="s2">&quot;TP</span><span class="se">\n</span><span class="s2">True Positive&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1"># -------------------------------------------------</span>
<span class="c1"># Plot</span>
<span class="c1"># -------------------------------------------------</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># ---- Row 1 ----</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">row1</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;Pred 0&quot;</span><span class="p">,</span> <span class="s2">&quot;Pred 1&quot;</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s2">&quot;True 0&quot;</span><span class="p">,</span> <span class="s2">&quot;True 1&quot;</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightgray&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightgray&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">structure_labels</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                    <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">linespacing</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                        <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>

<span class="c1"># ---- Row 2 ----</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">row2</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;Pred 0&quot;</span><span class="p">,</span> <span class="s2">&quot;Pred 1&quot;</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s2">&quot;True 0&quot;</span><span class="p">,</span> <span class="s2">&quot;True 1&quot;</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightgray&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightgray&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                    <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># -------------------------------------------------</span>
<span class="c1"># Class balance summary</span>
<span class="c1"># -------------------------------------------------</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_class_balance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">n_inactive</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">n_active</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">n_inactive</span> <span class="o">/</span> <span class="n">n_active</span> <span class="k">if</span> <span class="n">n_active</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">25s</span><span class="si">}</span><span class="s2"> | &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Inactive (0): </span><span class="si">{</span><span class="n">n_inactive</span><span class="si">:</span><span class="s2">5d</span><span class="si">}</span><span class="s2"> | &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Active (1): </span><span class="si">{</span><span class="n">n_active</span><span class="si">:</span><span class="s2">5d</span><span class="si">}</span><span class="s2"> | &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Ratio (0:1): </span><span class="si">{</span><span class="n">ratio</span><span class="si">:</span><span class="s2">6.2f</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>

<span class="c1"># Reconstruct full dataset labels (pre-split)</span>
<span class="n">y_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Class balance by dataset&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">90</span><span class="p">)</span>
<span class="n">print_class_balance</span><span class="p">(</span><span class="s2">&quot;Full dataset (original)&quot;</span><span class="p">,</span> <span class="n">y_full</span><span class="p">)</span>
<span class="n">print_class_balance</span><span class="p">(</span><span class="s2">&quot;Training set&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">print_class_balance</span><span class="p">(</span><span class="s2">&quot;Test set&quot;</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">print_class_balance</span><span class="p">(</span><span class="s2">&quot;Balanced training set&quot;</span><span class="p">,</span> <span class="n">y_train_bal</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/178054aa0e3f4d22ec1105b183008a6118fbd5f36ba0ba1a65c694db5ac71a0d.png" src="../../../_images/178054aa0e3f4d22ec1105b183008a6118fbd5f36ba0ba1a65c694db5ac71a0d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Class balance by dataset
------------------------------------------------------------------------------------------
Full dataset (original)   | Inactive (0):  6050 | Active (1):   743 | Ratio (0:1):   8.14
Training set              | Inactive (0):  5444 | Active (1):   669 | Ratio (0:1):   8.14
Test set                  | Inactive (0):   606 | Active (1):    74 | Ratio (0:1):   8.19
Balanced training set     | Inactive (0):   669 | Active (1):   669 | Ratio (0:1):   1.00
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-info">
<strong>Check your understanding</strong>
<br>
<p>1. Why do the training set and test set have the same inactive-to-active ratio as the full dataset, while the balanced training set does not? 
</p>
<p><strong>Hint:</strong>  Review <a href="https://rebelford.github.io/2026Cheminformatics/content/modules/10_SupervisedML/10_2_NB_model_construction_workflow.html#train-test-split-a-9-1-ratio"> module 10.2 section 1.5 Train-Test_Split</a></p>
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
    <summary>Answer</summary>
The <code>stratify=y</code> parameter setting ensured the test and training sets had the same active/inactive ratio as the original dataset. We then created the balanced training set by downsampling the inactives of the training set so that the number of inactives equaled the number of actives.
</details>
</div>
<br>
<p>2. In the test set, the model predicts 425 compounds as inactive, and 400 of those predictions are correct. In contrast, it predicts 255 compounds as active, but only 49 of those predictions are correct. Why does the model appear very reliable when predicting inactives, but unreliable when predicting actives?</p>
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
    <summary>Answer</summary>
This illustrates the effect of class prevalence on the reliability of model predictions. Although the classifier was trained on a balanced dataset and did not learn to favor one class over the other, it is evaluated on a test set where inactive compounds greatly outnumber active compounds.
<p>Because inactive compounds are common, most predictions of “inactive” are correct. In contrast, active compounds are rare, so when the model predicts “active,” it is far more likely to be wrong than right. As a result, predictions of “active” are unreliable, even though the model makes many such predictions.</p>
<p>This asymmetry does not arise from bias learned during training. It arises because class prevalence affects how trustworthy predictions are. This motivates the need for a metric that directly answers the question: when the model predicts a compound as active, how often is that prediction correct?</p>
</details>
</div>
<br>
<p>3. The confusion matrix for the balanced training set shows that the classifier correctly predicts roughly 70% of both active and inactive compounds. Why should this result not be interpreted as an estimate of real-world model performance, and why is it still useful to examine? </p>
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
    <summary>Answer</summary>
The balanced training set confusion matrix shows that the classifier makes roughly similar types of errors for actives and inactives, correctly classifying about 70% of each. However, this result does not represent real predictive performance, because these data were used to fit the model. Instead, it reflects how well the model fits the training distribution and whether it treats the two classes symmetrically.
<p>When the same model is applied to the test set, the confusion matrix changes substantially. The test set reflects the original class imbalance, where active compounds are rare. As a result, errors affecting the minority class dominate the interpretation, and predictions of “active” become unreliable.</p>
<p>This contrast illustrates the distinction between fitting and generalization. Performance on the training data reflects how well the model has learned patterns under controlled conditions, specifically, a balanced class distribution where both actives and inactives are equally represented. In this setting, the confusion matrix reveals whether the model treats the two classes symmetrically and whether it can separate them at all under idealized conditions.</p>
<p>Test-set performance, in contrast, evaluates how those learned patterns behave when the model is applied to unseen data drawn from the original, imbalanced population. Here, the same model must operate under realistic class prevalence, where active compounds are rare. The resulting confusion matrix therefore reflects not only what the model has learned, but how useful that learning is when confronted with the data conditions it would encounter in practice.</p>
</details>
</div>
<br>
<p>4. Why are the number of actual active compounds (FN and TP) the same in the balanced training and full training set?  That is for both, FN=187 and TP=482.
</p>
<p><strong>Hint:</strong>  Review <a href="https://rebelford.github.io/2026Cheminformatics/content/modules/10_SupervisedML/10_2_NB_model_construction_workflow.html#train-test-split-a-9-1-ratio"> module 10.2 section 1.5 Train-Test_Split</a></p>
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
    <summary>Answer</summary>
If you look at <a href="https://rebelford.github.io/2026Cheminformatics/content/modules/10_SupervisedML/10_2_NB_model_construction_workflow.html#balance-the-training-set-by-downsampling"> module 10.2 section 2.3 Balance the Training Set by Downsampling</a>, you will see that we set the number of inactives in the balanced training set to equal the number of actives present in the training data (669), and so these not only represent the same number of molecules, but the exact same molecules.
</details>
</div>
<br>
<p>5. If you were only told the total number of correct predictions made by this model, what important information would you be missing? Use the confusion matrix to explain why a single summary number is not sufficient.</p>
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
    <summary>Answer</summary>
A single summary number, such as the total number of correct predictions, does not reveal which compounds are being classified correctly or incorrectly. The confusion matrix shows that correct predictions are not evenly distributed across classes.
<p>In the test set, most correct predictions come from correctly identifying inactive compounds, while a large fraction of active compounds are misclassified. If we only looked at the total number of correct predictions, the model might appear to perform reasonably well, even though it is failing to identify most active compounds.</p>
<p>The confusion matrix separates correct and incorrect predictions by class and distinguishes different types of error. This allows us to distinguish between mistakes that involve falsely labeling a compound as active and mistakes that involve missing an active compound entirely. These distinctions are essential in scientific and regulatory contexts, where different errors have very different consequences.</p>
<p>This motivates the need for multiple evaluation metrics, each designed to quantify a different aspect of model behavior using the four values in the confusion matrix: true positives, true negatives, false positives, and false negatives.</p>
</details>
</div>
</div>
<p>The confusion matrix provides the raw information needed to evaluate a classifier, but it does not reduce that information to a single interpretable quantity. In the next section, we introduce evaluation metrics that summarize different aspects of model behavior using the four entries of the confusion matrix.</p>
<section id="confusion-matrix-based-evaluation-metrics">
<h2>2.1 Confusion Matrix Based Evaluation Metrics<a class="headerlink" href="#confusion-matrix-based-evaluation-metrics" title="Link to this heading">#</a></h2>
<p>The confusion matrix reveals which kinds of mistakes the model makes.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p><strong>Predicted Inactive</strong></p></th>
<th class="head"><p><strong>Predicted Active</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Actual Inactive</strong></p></td>
<td><p><strong>TN</strong> (True Negative)</p></td>
<td><p><strong>FP</strong> (False Positive)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Actual Active</strong></p></td>
<td><p><strong>FN</strong> (False Negative)</p></td>
<td><p><strong>TP</strong> (True Positive)</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="table-of-confusion-matrix-metrics">
<h2>2.2 Table of Confusion Matrix Metrics<a class="headerlink" href="#table-of-confusion-matrix-metrics" title="Link to this heading">#</a></h2>
<p>All the metrics below are derived from TN, TP, FN &amp; FP and summarize the model’s validity (mistakes) from different scientific perspectives.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>Mathematical Definition</p></th>
<th class="head"><p>What This Metric Tells Us</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Accuracy</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(\displaystyle \frac{TP + TN}{TP + TN + FP + FN}\)</span></p></td>
<td><p>What fraction of all predictions—active and inactive—were correct overall.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Precision</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(\displaystyle \frac{TP}{TP + FP}\)</span></p></td>
<td><p>When the model predicts “active,” how often is it actually correct?</p></td>
</tr>
<tr class="row-even"><td><p><strong>Sensitivity (Recall)</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(\displaystyle \frac{TP}{TP + FN}\)</span></p></td>
<td><p>Of all truly active compounds, how many did the model successfully identify?</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Specificity</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(\displaystyle \frac{TN}{TN + FP}\)</span></p></td>
<td><p>Of all truly inactive compounds, how many did the model correctly reject?</p></td>
</tr>
<tr class="row-even"><td><p><strong>Balanced Accuracy</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(\displaystyle \frac{\text{Sensitivity} + \text{Specificity}}{2}\)</span></p></td>
<td><p>How well the model performs across both classes, even when the dataset is imbalanced.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>F1 Score</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(\displaystyle \frac{2,(\text{Precision}\times\text{Sensitivity})}{\text{Precision} + \text{Sensitivity}}\)</span></p></td>
<td><p>A single score that balances finding actives with avoiding false positives.</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Quick Rules of Thumb:</strong></p>
<ul class="simple">
<li><p>If accuracy is high but balanced accuracy is low → suspect class imbalance.</p></li>
<li><p>Use balanced accuracy when your dataset has a lot more inactives than actives.</p></li>
<li><p>Sensitivity is important when missing an active could be costly (e.g., in drug screening).</p></li>
<li><p>Specificity is important when false positives are costly (e.g., expensive follow-up experiments).</p></li>
<li><p>AUC-ROC gives a broader view of model quality — useful even when you’re not picking a classification threshold yet.</p></li>
</ul>
</section>
<section id="id1">
<h2>2.3. Confusion Matrix Based Evaluation Metrics<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>To answer the question “Is the model good enough?”, we rely on key metrics calculated from the confusion matrix:</p>
<section id="accuracy">
<h3>2.3.1 Accuracy<a class="headerlink" href="#accuracy" title="Link to this heading">#</a></h3>
<div class="alert alert-block alert-success"> 
<p>
<center>
    <strong>Accuracy: The fraction of total predictions that the model classified correctly.</strong></center>
</p>
\[ \frac{TP + TN}{TP + TN + FP + FN} \]
<div class="alert alert-block alert-info">
<details>
<summary>Explanation</summary>
<p><strong>Definition</strong>
Accuracy is defined as:</p>
<p><span class="math notranslate nohighlight">\( \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} \)</span></p>
<p>In words, accuracy is the number of correct predictions divided by the total number of predictions.</p>
<p><strong>Interpretation</strong></p>
<ul class="simple">
<li><p>An accuracy of 1.0 (100%) means the model made no classification errors.</p></li>
<li><p>An accuracy of 0.5 (50%) for a binary classifier is equivalent to random guessing <em>if</em> the classes are balanced.</p></li>
<li><p>Accuracy treats false positives and false negatives equally, which is not always desirable depending on the application.</p></li>
</ul>
<p><strong>When Accuracy Works Well</strong>
Accuracy is most informative when:</p>
<ul class="simple">
<li><p>The dataset is balanced (roughly equal numbers of positive and negative samples).</p></li>
<li><p>The cost of false positives and false negatives is similar.</p></li>
</ul>
<p><strong>When Accuracy Can Be Misleading</strong><br />
Accuracy can give a false sense of model quality when:</p>
<ul class="simple">
<li><p>The classes are highly imbalanced.</p></li>
<li><p>One type of error (FP or FN) is much more costly than the other.</p></li>
</ul>
<p>For example, in a dataset where 95% of compounds are inactive, a model that predicts <em>everything</em> as inactive will achieve 95% accuracy—despite having no practical value for identifying active compounds.</p>
</details>
</div>
</div>
</section>
<section id="precision">
<h3>2.3.2 Precision<a class="headerlink" href="#precision" title="Link to this heading">#</a></h3>
<div class="alert alert-block alert-success"> 
<p>
<center><strong>Precision: When the model predicts a compound is active, how often is that prediction correct? </strong></center>
</p>    
\[ \frac{TP}{TP + FP}  \]
<div class="alert alert-block alert-info">
<details>
<summary>Explanation</summary>
<p><strong>Definition</strong><br />
Precision is defined as:</p>
<p><span class="math notranslate nohighlight">\( \text{Precision} = \frac{TP}{TP + FP} \)</span></p>
<p>In words, precision is the number of correctly predicted positives divided by the total number of positive predictions made by the model.</p>
<p><strong>Interpretation</strong></p>
<ul class="simple">
<li><p>A precision of 1.0 (100%) means that every compound predicted as active truly is active.</p></li>
<li><p>A lower precision indicates that many predicted actives are actually inactive (false positives).</p></li>
<li><p>Precision focuses <em>only</em> on positive predictions and ignores true negatives.</p></li>
</ul>
<p><strong>Why Precision Matters</strong></p>
<p>Precision is especially important when the cost of false positives is high. In cheminformatics, a false positive corresponds to an inactive compound being predicted as active, which can lead to wasted experimental effort, time, and resources.</p>
<p><strong>When Precision Is the Right Metric</strong></p>
<p>Precision is most informative when:</p>
<ul class="simple">
<li><p>You care more about the <em>quality</em> of predicted positives than the total number found.</p></li>
<li><p>False positives are more costly than false negatives.</p></li>
<li><p>You want high confidence that predicted actives are truly active.</p></li>
</ul>
<p><strong>Trade-off with Recall</strong></p>
<p>Precision is often in tension with recall. A model can achieve high precision by being very conservative and predicting “active” only when it is very confident, but this may cause it to miss many true actives (low recall). Understanding this trade-off is essential when evaluating classification models.</p>
</details>
</div>
</div></section>
<section id="sensitivity-recall-true-positive-rate">
<h3>2.3.3 Sensitivity (Recall / True Positive Rate)<a class="headerlink" href="#sensitivity-recall-true-positive-rate" title="Link to this heading">#</a></h3>
<div class="alert alert-block alert-success"> 
<p><center><strong>Sensitivity: Of all the truly active compounds, how many did the model successfully detect?</strong></center></p>
<div class="math notranslate nohighlight">
\[\frac{TP}{TP + FN}\]</div>
<div class="alert alert-block alert-info">
<details>
<summary>Explanation</summary>
<p><strong>Definition</strong></p>
<p><span class="math notranslate nohighlight">\( \text{Sensitivity} = \frac{TP}{TP + FN} \)</span></p>
<p>In words, sensitivity is the fraction of true positives that the model correctly identifies.</p>
<p><strong>Interpretation</strong></p>
<ul class="simple">
<li><p>A sensitivity of 1.0 (100%) means the model found <em>all</em> active compounds.</p></li>
<li><p>A low sensitivity indicates that many active compounds were missed (false negatives).</p></li>
<li><p>Sensitivity ignores false positives entirely and focuses only on how well positives are recovered.</p></li>
</ul>
<p><strong>Why Sensitivity Matters</strong></p>
<p>Sensitivity is critical when missing a positive result is costly. In chemical screening, a false negative corresponds to an active compound being incorrectly classified as inactive, potentially causing a promising candidate to be discarded prematurely.</p>
<p><strong>When Sensitivity Is the Right Metric</strong></p>
<p>Sensitivity is most informative when:</p>
<ul class="simple">
<li><p>You want to capture as many true actives as possible.</p></li>
<li><p>False negatives are more costly than false positives.</p></li>
<li><p>The goal is early-stage screening, where it is acceptable to tolerate some false positives in order to avoid missing real actives.</p></li>
</ul>
<p><strong>Trade-off with Precision</strong></p>
<p>Sensitivity often trades off with precision. A model can achieve high sensitivity by predicting “active” more liberally, but this may increase the number of false positives and reduce precision. Balancing sensitivity and precision depends on the scientific and practical goals of the analysis.</p>
</details>
</div>
</div></section>
<section id="specificity-true-negative-rate">
<h3>2.3.4 Specificity (True Negative Rate)<a class="headerlink" href="#specificity-true-negative-rate" title="Link to this heading">#</a></h3>
<div class="alert alert-block alert-success"> 
<p><center><strong>Specificity: Of all the truly inactive compounds, how many did the model correctly classify as inactive?</strong></center></p>
    <br>
\[ \frac{TN}{TN + FP} \]
<div class="alert alert-block alert-info">
<details>
<summary>Explanation</summary
<p><strong>Definition</strong></p>
<p><span class="math notranslate nohighlight">\( \text{Specificity} = \frac{TN}{TN + FP} \)</span></p>
<p>In words, specificity is the fraction of true negatives that the model correctly identifies.</p>
<p><strong>Interpretation</strong></p>
<ul class="simple">
<li><p>A specificity of 1.0 (100%) means the model made no false-positive errors.</p></li>
<li><p>A lower specificity indicates that many inactive compounds were incorrectly labeled as active.</p></li>
<li><p>Specificity ignores false negatives and focuses exclusively on negative predictions.</p></li>
</ul>
<p><strong>Why Specificity Matters</strong></p>
<p>Specificity is important when false positives are costly. In chemical screening, a false positive corresponds to an inactive compound being flagged as active, which can lead to unnecessary follow-up experiments, wasted reagents, and inefficient use of laboratory resources.</p>
<p><strong>When Specificity Is the Right Metric</strong></p>
<p>Specificity is most informative when:</p>
<ul class="simple">
<li><p>You want to confidently rule out inactive compounds.</p></li>
<li><p>False positives are more costly than false negatives.</p></li>
<li><p>Later-stage screening or validation requires high confidence in negative classifications.</p></li>
</ul>
<p><strong>Relationship to Sensitivity</strong></p>
<p>Specificity is complementary to sensitivity. Increasing sensitivity often decreases specificity, and vice versa. Together, sensitivity and specificity describe how well a model separates the positive and negative classes across the full dataset.</p>
</details>
</div>
</div></section>
<section id="balanced-accuracy">
<h3>2.3.5 Balanced Accuracy<a class="headerlink" href="#balanced-accuracy" title="Link to this heading">#</a></h3>
<div class="alert alert-block alert-success"> 
<p><center><strong>Balanced Accuracy: How well does the model perform on each class, on average?</strong></center></p>
<p>[ \frac{1}{2}\left( \frac{TP}{TP + FN} + \frac{TN}{TN + FP} \right) ]</p>
<div class="alert alert-block alert-info">
<details>
<summary>Explanation</summary>
<p><strong>Definition</strong><br />
Balanced accuracy is defined as the average of sensitivity (recall) and specificity:</p>
<p><span class="math notranslate nohighlight">\( \text{Balanced Accuracy} = \frac{1}{2}\left( \frac{TP}{TP + FN} + \frac{TN}{TN + FP} \right) \)</span></p>
<p>Equivalently:</p>
<p><span class="math notranslate nohighlight">\( \text{Balanced Accuracy} = \frac{\text{Sensitivity} + \text{Specificity}}{2} \)</span></p>
<p><strong>Interpretation</strong></p>
<ul class="simple">
<li><p>A balanced accuracy of 1.0 (100%) means the model perfectly classifies both actives and inactives.</p></li>
<li><p>A balanced accuracy of 0.5 indicates performance no better than random guessing for a binary classifier.</p></li>
<li><p>Balanced accuracy penalizes models that perform well on one class but poorly on the other.</p></li>
</ul>
<p><strong>Why Balanced Accuracy Matters</strong></p>
<p>Balanced accuracy is particularly valuable when working with imbalanced datasets, which are common in cheminformatics and biological screening. It prevents a model from appearing artificially strong simply by predicting the majority class well.</p>
<p>For example, if most compounds are inactive, a model that predicts everything as inactive may achieve high standard accuracy—but its balanced accuracy will be low because sensitivity is poor.</p>
<p><strong>When Balanced Accuracy Is the Right Metric</strong></p>
<p>Balanced accuracy is most informative when:</p>
<ul class="simple">
<li><p>The classes are imbalanced.</p></li>
<li><p>You want equal emphasis on detecting actives and correctly rejecting inactives.</p></li>
<li><p>You are comparing different models fairly across the same dataset.</p></li>
</ul>
</details>
</div>
</div></section>
<section id="f1-score">
<h3>2.3.6 F1 Score<a class="headerlink" href="#f1-score" title="Link to this heading">#</a></h3>
<div class="alert alert-block alert-success"> 
<p><center><strong>The F1 score balances two different ways of judging model performance: how many real actives the model finds (recall), and how trustworthy its active predictions are (precision). It is high only when both are reasonably good.</strong></center></p>
<div class="math notranslate nohighlight">
\[2 \times \frac{\text{Precision} \times \text{Sensitivity}}{\text{Precision} + \text{Sensitivity}}\]</div>
<div class="alert alert-block alert-info">
<details>
<summary>Explanation</summary>
<p><strong>Definition</strong><br />
The F1 score is defined as the harmonic mean of precision and sensitivity (recall):</p>
<p><span class="math notranslate nohighlight">\( \text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Sensitivity}}{\text{Precision} + \text{Sensitivity}} \)</span></p>
<p>Substituting the confusion matrix terms:</p>
<p><span class="math notranslate nohighlight">\( \text{F1 Score} = \frac{2TP}{2TP + FP + FN} \)</span></p>
<p><strong>Interpretation</strong></p>
<ul class="simple">
<li><p>An F1 score of 1.0 (100%) means the model has perfect precision and perfect sensitivity.</p></li>
<li><p>A low F1 score indicates poor performance in either precision, sensitivity, or both.</p></li>
<li><p>The F1 score does not consider true negatives and focuses entirely on the positive class.</p></li>
</ul>
<p><strong>Why the F1 Score Matters</strong></p>
<p>The F1 score is valuable when you want a single metric that reflects a balance between:</p>
<ul class="simple">
<li><p>avoiding false positives (precision), and</p></li>
<li><p>avoiding false negatives (sensitivity).</p></li>
</ul>
<p>In chemical screening, this is often desirable when neither missing active compounds nor pursuing too many inactive compounds is acceptable.</p>
<p><strong>When the F1 Score Is the Right Metric</strong></p>
<p>The F1 score is most informative when:</p>
<ul class="simple">
<li><p>The dataset is imbalanced.</p></li>
<li><p>Both false positives and false negatives are costly.</p></li>
<li><p>You want a single number to compare models that trade off precision and sensitivity differently.</p></li>
</ul>
<p><strong>Limitations of the F1 Score</strong></p>
<p>While useful, the F1 score has limitations:</p>
<ul class="simple">
<li><p>It ignores true negatives entirely.</p></li>
<li><p>It does not distinguish between different types of errors beyond FP and FN.</p></li>
<li><p>Two models with very different precision–recall trade-offs can have the same F1 score.</p></li>
</ul>
<p>For these reasons, the F1 score should be interpreted alongside other metrics rather than used alone.</p>
</details>
</div>
</div></section>
</section>
<section id="interpreting-differences-between-training-and-test-performance">
<h2>2.4 Interpreting Differences Between Training and Test Performance<a class="headerlink" href="#interpreting-differences-between-training-and-test-performance" title="Link to this heading">#</a></h2>
<p>When evaluating a supervised learning model, it is important to compare performance on the training set to performance on the test set. These two evaluations answer different questions:</p>
<ul class="simple">
<li><p>Training set performance tells us how well the model learned patterns from the data it was trained on.</p></li>
<li><p>Test set performance tells us how well those learned patterns generalize to previously unseen data.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute classification metrics derived from the confusion matrix.</span>
<span class="sd">    Returns a dictionary of metrics.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="n">accuracy</span>  <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>
    <span class="n">recall</span>    <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>   <span class="c1"># sensitivity</span>
    <span class="n">specificity</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>
    <span class="n">balanced_accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">recall</span> <span class="o">+</span> <span class="n">specificity</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">))</span> <span class="k">if</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">,</span>
        <span class="s2">&quot;Precision&quot;</span><span class="p">:</span> <span class="n">precision</span><span class="p">,</span>
        <span class="s2">&quot;Sensitivity&quot;</span><span class="p">:</span> <span class="n">recall</span><span class="p">,</span>
        <span class="s2">&quot;Specificity&quot;</span><span class="p">:</span> <span class="n">specificity</span><span class="p">,</span>
        <span class="s2">&quot;Balanced Accuracy&quot;</span><span class="p">:</span> <span class="n">balanced_accuracy</span><span class="p">,</span>
        <span class="s2">&quot;F1 Score&quot;</span><span class="p">:</span> <span class="n">f1</span><span class="p">,</span>
    <span class="p">}</span>


<span class="c1"># -------------------------------------------------</span>
<span class="c1"># Compute metrics</span>
<span class="c1"># -------------------------------------------------</span>
<span class="n">metrics_test</span> <span class="o">=</span> <span class="n">compute_metrics</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span>
<span class="n">metrics_train_bal</span> <span class="o">=</span> <span class="n">compute_metrics</span><span class="p">(</span><span class="n">y_train_bal</span><span class="p">,</span> <span class="n">y_train_bal_pred</span><span class="p">)</span>


<span class="c1"># -------------------------------------------------</span>
<span class="c1"># Print results</span>
<span class="c1"># -------------------------------------------------</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TEST SET PERFORMANCE&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">metrics_test</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">:</span><span class="s2">18s</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">BALANCED TRAINING SET PERFORMANCE&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">metrics_train_bal</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">:</span><span class="s2">18s</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TEST SET PERFORMANCE
Accuracy           = 0.6603
Precision          = 0.1922
Sensitivity        = 0.6622
Specificity        = 0.6601
Balanced Accuracy  = 0.6611
F1 Score           = 0.2979

BALANCED TRAINING SET PERFORMANCE
Accuracy           = 0.7018
Precision          = 0.6945
Sensitivity        = 0.7205
Specificity        = 0.6831
Balanced Accuracy  = 0.7018
F1 Score           = 0.7073
</pre></div>
</div>
</div>
</div>
<p>This table compares performance on the training and test sets using multiple evaluation metrics. The goal is not to optimize any single number, but to understand how model behavior changes when applied to unseen data. Differences between training and test performance reveal how well the learned patterns generalize and which types of errors dominate.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>Training Set</p></th>
<th class="head"><p>Test Set</p></th>
<th class="head"><p>What We Learn</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Accuracy</strong></p></td>
<td><p>0.702</p></td>
<td><p>0.660</p></td>
<td><p>Training and test accuracy are similar, suggesting the model is not severely overfitting. The model has learned some real signal, but overall performance remains modest.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Precision</strong></p></td>
<td><p>0.695</p></td>
<td><p>0.192</p></td>
<td><p>Precision collapses on the test set because the test data are highly imbalanced. Even a moderate false positive rate produces many false positives when inactive compounds dominate.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Sensitivity (Recall)</strong></p></td>
<td><p>0.721</p></td>
<td><p>0.662</p></td>
<td><p>The model continues to identify a substantial fraction of true actives in unseen data, indicating that activity-related signal generalizes reasonably well.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Specificity</strong></p></td>
<td><p>0.683</p></td>
<td><p>0.660</p></td>
<td><p>Specificity remains similar between training and test sets, suggesting the model’s handling of inactive compounds is relatively stable.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Balanced Accuracy</strong></p></td>
<td><p>0.702</p></td>
<td><p>0.661</p></td>
<td><p>Balanced accuracy remains well above random (0.5), indicating meaningful—but imperfect—separation of actives and inactives.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>F1 Score</strong></p></td>
<td><p>0.707</p></td>
<td><p>0.298</p></td>
<td><p>The large drop reflects the combined effect of reasonable sensitivity but very low precision on the imbalanced test set, highlighting the cost of false positives.</p></td>
</tr>
</tbody>
</table>
</div>
<p>At first glance, these results may seem contradictory. Several metrics suggest that the model has learned meaningful structure and generalizes reasonably well, while others indicate very poor performance on the test set. In particular, the sharp decline in precision and F1 score stands in contrast to the relatively stable sensitivity, specificity, and balanced accuracy. To understand why these metrics behave so differently, and what that tells us about the model, we need to take a closer look at how class imbalance and decision thresholds affect evaluation.</p>
<div class="alert alert-block alert-info">
<strong>Deep Dive:</strong> Why Do Precision and F1 Collapse on the Test Set?
<br>
<div class ="alert-block alert-success">
<details>
<summary>Explanation</summary>
<br>
<p>The dramatic drop in precision and F1 score on the test set is not primarily a failure of the model, it is a consequence of class imbalance.</p>
<p><strong>Precision</strong> answers the question: <em> Of the compounds predicted to be active, how many truly are active?”</em> In an imbalanced dataset, inactive compounds vastly outnumber actives. As a result, even a modest false positive rate can generate many false positives, overwhelming the true positives and driving precision downward.</p>
<p><strong>F1 score</strong> combines precision and sensitivity into a single metric. Because precision is very low on the test set, the F1 score also collapses, even though sensitivity remains reasonably high.</p>
<p>Importantly, this does <em>not</em> mean the model cannot detect actives. It means that, at the chosen decision threshold, many inactive compounds are incorrectly labeled as active. This distinction is critical: sensitivity and specificity describe class-conditional behavior, while precision depends strongly on class prevalence. This is why confusion-matrix-based metrics must be interpreted alongside dataset balance, and why a ranking-based evaluation (ROC–AUC) is a necessary next step.</p>
</details>
</div>
</div>
<p>2.4.1 Interpreting Metric Disagreements and the Role of Decision Thresholds</p>
<p>At first glance, the results in the table above may appear contradictory. Several metrics, such as sensitivity, specificity, and balanced accuracy, suggest that the model has learned meaningful structure and generalizes reasonably well to unseen data. At the same time, precision and F1 score collapse dramatically on the test set, indicating very poor performance.</p>
<p>This apparent contradiction arises because different metrics answer different questions, and some of those questions depend strongly on class prevalence and on how model scores are converted into class labels.</p>
<p>Precision asks: Of the compounds predicted to be active, how many truly are active? In the imbalanced test set, inactive compounds vastly outnumber actives. As a result, even a modest false positive rate produces many false positives, overwhelming the relatively small number of true positives and driving precision downward. Because the F1 score combines precision and sensitivity, it also collapses—even though sensitivity remains reasonably high.</p>
<p>Importantly, this does not mean the model cannot detect actives. Sensitivity shows that a substantial fraction of true actives are still being identified. Instead, the problem lies in how the model’s scores are translated into class labels at the chosen decision threshold. At this cutoff, many inactive compounds are labeled as active, making positive predictions unreliable.</p>
<p>Many classifiers do not directly decide whether a compound is active or inactive. Instead, they assign a score indicating how strongly a compound resembles known actives. A decision threshold is the cutoff used to convert that score into a discrete label. Compounds with scores above the threshold are labeled “active,” while those below the threshold are labeled “inactive.” Changing the threshold does not alter the model or the data, it changes only how predictions are turned into labels, and therefore which outcomes are counted as true positives, false positives, true negatives, and false negatives.</p>
<p>This distinction is critical. Metrics such as sensitivity and specificity describe class-conditional behavior, while precision and F1 depend strongly on both class prevalence and the decision threshold. All confusion-matrix-based metrics therefore describe model performance at one specific cutoff.</p>
<p>The key takeaway is that a model may contain useful discriminatory information while still appearing unreliable at a particular threshold. Before deciding whether a model is truly useful, we need a way to evaluate its ability to separate actives from inactives independently of any single decision threshold.</p>
<p>This motivates a shift from classification-based evaluation to ranking-based evaluation, where we ask not “Is this compound classified as active?” but rather “Does the model assign higher scores to actives than to inactives across all possible thresholds?” In the next section, we introduce ROC curves and the ROC–AUC metric to answer exactly this question.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="under-the-hood-confusion-matrices-thresholds-and-probability-scores">
<h1>3. Under the Hood: Confusion Matrices, Thresholds and Probability Scores<a class="headerlink" href="#under-the-hood-confusion-matrices-thresholds-and-probability-scores" title="Link to this heading">#</a></h1>
<p>Up to this point, we have evaluated our model using confusion matrices derived from <code class="docutils literal notranslate"><span class="pre">.predict()</span></code>. This is a natural starting point: confusion matrices provide an explicit, interpretable summary of how a binary classifier performs at a particular decision rule.</p>
<p>However, <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> represents only the final step in the model’s reasoning. Internally, the classifier does not begin by assigning class labels (active or inactive). Instead, it computes a continuous probability score (0 to 1) for each compound that reflects how strongly it resembles known actives relative to inactives.</p>
<p>The method <code class="docutils literal notranslate"><span class="pre">.predict_proba()</span></code> exposes these scores directly. For a binary classifier, it produces one probability estimate per compound indicating the model’s confidence that the compound belongs to the active class. A decision threshold is then used to convert these scores into class labels. By default, scikit-learn uses a threshold of 0.5, and the output of the confusion matrix generated by <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> was based on this value.  This choice is not inherent to the model and we can explore the effect of raising or lowering the threshold.</p>
<p>Each choice of threshold produces a different set of predicted labels, and therefore a different confusion matrix. If the threshold is set to 0, all compounds are predicted active. If the threshold is set to 1, only compounds with a probability score of exactly 1 would be predicted active, which in practice usually means none.</p>
<p>Conceptually,</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># Conceptual logic (not actual sklearn code)
threshold = 0.5 # default value used by .predict()
score = P(active)
if score ≥ threshold:
    predict active
else:
    predict inactive
</pre></div>
</div>
<div class="alert alert-block alert-info">
<strong>Reality Check: What Do We Mean by “Threshold”?</strong>  
<p>The word <em>threshold</em> appears in both experimental science and machine learning, but it refers to two very different ideas. Confusing these meanings can make model evaluation feel mysterious or misleading.</p>
<p><strong>Discussion question:</strong><br>
When we talk about a “threshold” in machine learning, are we talking about the same kind of threshold that defines whether a compound is active or inactive in a bioassay?</p>
<div class="alert alert-block alert-success">
<details>
  <summary>Explanation</summary>
  <p><strong>No — these are fundamentally different thresholds.</strong></p>
  <p><strong>Experimental (bioassay) threshold:</strong><br>
  In an assay, a threshold is part of how the <em>labels are defined</em>. For example, a compound may be labeled “active” if its IC<sub>50</sub> is below a specified cutoff. This threshold reflects experimental design and scientific judgment. Once chosen, it defines the ground truth labels used for modeling.</p>
  <p><strong>Model (decision) threshold:</strong><br>
  In machine learning, a threshold does <em>not</em> change the experimental labels. Instead, it controls how a model’s <em>continuous output</em> (such as a predicted probability of activity) is converted into a hard class prediction (active vs inactive).</p>
  <p>For example, a model might assign a compound a probability of 0.62 for being active. With a decision threshold of 0.50, the model predicts “active.” With a threshold of 0.70, the same compound would be predicted “inactive.” The experimental label has not changed — only the model’s decision rule has.</p>
</details>
</div>
</div>
<section id="probabilistic-evaluation-predict-proba">
<h2>3.1 Probabilistic Evaluation (<code class="docutils literal notranslate"><span class="pre">.predict_proba</span></code>)<a class="headerlink" href="#probabilistic-evaluation-predict-proba" title="Link to this heading">#</a></h2>
<p>The following code cell prints the probabilistic scores for the first 5 compounds</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Imports</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">BernoulliNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">confusion_matrix</span><span class="p">,</span>
    <span class="n">accuracy_score</span><span class="p">,</span>
    <span class="n">roc_auc_score</span><span class="p">,</span>
    <span class="n">roc_curve</span>
<span class="p">)</span>

<span class="c1">#2 Load arrays (uncomment if SPLIT_ROOT is not in memory)</span>
<span class="n">SPLIT_ROOT</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data/AID743139/splits/90_10/arrays&quot;</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;X_train.npy&quot;</span><span class="p">)</span>
<span class="n">X_test</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;X_test.npy&quot;</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;y_train.npy&quot;</span><span class="p">)</span>
<span class="n">y_test</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;y_test.npy&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># 3. Balance the training set</span>
<span class="n">idx_inactives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">idx_actives</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">num_actives</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx_actives</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">idx_inactives_downsampled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
    <span class="n">idx_inactives</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="n">num_actives</span><span class="p">,</span>
    <span class="n">replace</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">X_train_bal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">idx_inactives_downsampled</span><span class="p">],</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">idx_actives</span><span class="p">]</span>
<span class="p">))</span>

<span class="n">y_train_bal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span>
    <span class="n">y_train</span><span class="p">[</span><span class="n">idx_inactives_downsampled</span><span class="p">],</span>
    <span class="n">y_train</span><span class="p">[</span><span class="n">idx_actives</span><span class="p">]</span>
<span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_train_bal</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train_bal</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># 4 Fit model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_bal</span><span class="p">,</span> <span class="n">y_train_bal</span><span class="p">)</span>

<span class="c1">#5. Get probablilty scores</span>
<span class="n">y_test_proba</span>  <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">y_train_proba</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_bal</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;First 5 test set probabilities: </span><span class="si">{</span><span class="n">y_test_proba</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;First 5 train set probabilities: </span><span class="si">{</span><span class="n">y_train_proba</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(6113, 162) (6113,)
(680, 162) (680,)
(1338, 162) (1338,)
First 5 test set probabilities: [9.83971842e-06 4.26106949e-01 9.93414890e-01 5.15784297e-02
 1.13849817e-01]
First 5 train set probabilities: [3.42145750e-01 1.25869415e-01 1.61529249e-01 9.99013227e-01
 7.40150342e-06]
</pre></div>
</div>
</div>
</div>
<p>To make these easier to work with we will load them into a pandas dataframe</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="n">y_test_proba_full</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">df_proba_head</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">y_test_proba_full</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;P(inactive)&quot;</span><span class="p">,</span> <span class="s2">&quot;P(active)&quot;</span><span class="p">]</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">y_test_proba_full</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_test_proba_full</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">df_proba_head</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
(680, 2)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>P(inactive)</th>
      <th>P(active)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.999990</td>
      <td>0.000010</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.573893</td>
      <td>0.426107</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.006585</td>
      <td>0.993415</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.948422</td>
      <td>0.051578</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.886150</td>
      <td>0.113850</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="alert alert-block alert-success"> 
<strong>Check Your Understanding:</strong> 
<p>
Using the default threshold of <code>.predict()</code>, identify which of the above compound index numbers is associated with an active prediction.
</p>    
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
    <summary>Answer</summary>
The default threshold is 0.5, so only number 2 with a value of 0.993415
</details>
</div>
<p>
If you changed the threshold to 0.3, which index numbers are associated with an active compound?
</p>    
  <div style="
    background-color: #efffff;
    color: #000000;
    padding: 10px;
    border-radius: 4px;
    border: 1px solid #dddddd;
    margin-top: 10px;
  ">
<details>
    <summary>Answer</summary>
One (0.425107) and two (0.993415) are both above the 0.3 threshold
</details>
</div>
</div>
</section>
<section id="recover-cids-of-compounds">
<h2>3.2 Recover CIDs of compounds<a class="headerlink" href="#recover-cids-of-compounds" title="Link to this heading">#</a></h2>
<p>The NumPy feature matrices and label vectors used by scikit-learn are designed for numerical computation and do not contain chemical identifiers. When the dataset was split into training and test sets, we saved separate CSV files that record which chemical identifiers (PubChem CIDs) belong to each split. These files preserve the alignment between array rows and chemical identity.</p>
<p>We can now reload the CID file for the test set and associate each probability score produced by the model with the specific compound it refers to. This allows us to interpret model outputs in chemical terms without embedding identifiers directly into the feature arrays.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">SPLIT_NAME</span> <span class="o">=</span> <span class="s2">&quot;90_10&quot;</span>

<span class="n">SPLIT_ROOT</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data/AID743139/splits&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="n">SPLIT_NAME</span>
<span class="n">ARRAYS_ROOT</span> <span class="o">=</span> <span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;arrays&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_test_proba</span> <span class="o">=</span> <span class="n">df_test_cids</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">df_test_proba</span><span class="p">[</span><span class="s2">&quot;P(active)&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test_proba</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df_test_proba</span><span class="o">.</span><span class="n">tail</span><span class="p">())</span>
<span class="n">df_test_proba</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>         cid     P(active)
675     6924  5.175899e-07
676    60699  9.999946e-01
677  5284366  6.910921e-01
678     8189  6.185480e-05
679    76748  5.687925e-01
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cid</th>
      <th>P(active)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5634</td>
      <td>0.000010</td>
    </tr>
    <tr>
      <th>1</th>
      <td>70754</td>
      <td>0.426107</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7195</td>
      <td>0.993415</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3965</td>
      <td>0.051578</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5748</td>
      <td>0.113850</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load true test labels</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ARRAYS_ROOT</span> <span class="o">/</span> <span class="s2">&quot;y_test.npy&quot;</span><span class="p">)</span>

<span class="n">df_test_proba</span> <span class="o">=</span> <span class="n">df_test_cids</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">df_test_proba</span><span class="p">[</span><span class="s2">&quot;P(active)&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test_proba</span>
<span class="n">df_test_proba</span><span class="p">[</span><span class="s2">&quot;y_true&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test</span>

<span class="n">df_test_proba</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cid</th>
      <th>P(active)</th>
      <th>y_true</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5634</td>
      <td>0.000010</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>70754</td>
      <td>0.426107</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7195</td>
      <td>0.993415</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3965</td>
      <td>0.051578</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5748</td>
      <td>0.113850</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="alert alert-block alert-success"> 
<strong>Check Your Understanding:</strong> 
<p>
Using the default decision threshold applied by <code>.predict()</code> (approximately 0.5), which of the compound index numbers shown above would be classified as <em>active</em>?
</p>    
<div style="
  background-color: #efffff;
  color: #000000;
  padding: 10px;
  border-radius: 4px;
  border: 1px solid #dddddd;
  margin-top: 10px;
">
<details>
  <summary>Answer</summary>
Only index 2 would be classified as active, because its predicted probability
(<code>P(active) = 0.993415</code>) exceeds the default threshold of 0.5.
All other compounds have probabilities below the threshold and are therefore
classified as inactive.
</details>
</div>
<p>
At this same threshold, which compound index represents a <em>false positive</em>, and why?
</p>    
<div style="
  background-color: #efffff;
  color: #000000;
  padding: 10px;
  border-radius: 4px;
  border: 1px solid #dddddd;
  margin-top: 10px;
">
<details>
  <summary>Answer</summary>
Index 2 is a false positive. Although it is predicted as active
(<code>P(active) = 0.993415</code>), its true label is inactive
(<code>y_true = 0</code>). This illustrates that a high predicted probability
does not guarantee a correct classification.
</details>
</div>
</div>
<p>At this point, we have all the pieces needed to move beyond single-threshold evaluation. We have continuous probability scores for each compound, an understanding of how thresholds convert those scores into classifications, and a way to associate model outputs with real chemical identities.</p>
<p>Rather than committing to one particular threshold, we now ask a broader question: How does model performance change across all possible decision thresholds? The ROC curve provides a systematic way to answer this question</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="roc-auc-threshold-independent-performance">
<h1>4. ROC/AUC: Threshold-Independent Performance<a class="headerlink" href="#roc-auc-threshold-independent-performance" title="Link to this heading">#</a></h1>
<p>Up to this point, we have seen how a classifier assigns probability scores to compounds and how a decision threshold converts those scores into class predictions. Changing the threshold changes how many compounds are predicted active, which in turn changes the confusion matrix. This raises a fundamental question:</p>
<blockquote>
<div><p>Which threshold gives the most true positives while producing the fewest false positives?</p>
</div></blockquote>
<p>That question captures the core tension in binary classification. Raising the threshold makes the model conservative (fewer false positives, more missed actives). Lowering the threshold makes the model permissive (more actives found, but also more false positives). The ROC curve provides a way to study this trade-off without committing to a single threshold.</p>
<section id="from-confusion-matrices-to-rates">
<h2>4.1 From confusion matrices to rates<a class="headerlink" href="#from-confusion-matrices-to-rates" title="Link to this heading">#</a></h2>
<p>Each confusion matrix summarizes model behavior at one specific threshold, but the raw counts (TP, FP, TN, FN) depend on the size and balance of the dataset. A rate is a way of normalizing the raw counts so they are expressed as fractions of a relevant whole, rather than as absolute numbers.</p>
<ul class="simple">
<li><p><strong>True Positive Rate (TPR)</strong>  Fraction of truly active compounds that are correctly identified (also called sensitivity or recall)
$<span class="math notranslate nohighlight">\(\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}}\)</span>$</p></li>
<li><p><strong>False Positive Rate (FPR)</strong>
Fraction of inactive compounds that are incorrectly predicted active
$<span class="math notranslate nohighlight">\( \text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}\)</span>$
Using rates allows us to compare thresholds on equal footing, independent of how many actives or inactives are present.</p></li>
</ul>
<blockquote>
<div><p>Our goal: maximize the true positive rate while minimizing the false positive rate.</p>
</div></blockquote>
</section>
<section id="roc-curves-and-decision-thresholds">
<h2>4.2 ROC Curves and Decision Thresholds<a class="headerlink" href="#roc-curves-and-decision-thresholds" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Imports</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">BernoulliNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">roc_auc_score</span><span class="p">,</span>
    <span class="n">roc_curve</span>
<span class="p">)</span>

<span class="c1">#2 Load arrays (uncomment if SPLIT_ROOT is not in memory)</span>
<span class="n">SPLIT_ROOT</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data/AID743139/splits/90_10/arrays&quot;</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;X_train.npy&quot;</span><span class="p">)</span>
<span class="n">X_test</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;X_test.npy&quot;</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;y_train.npy&quot;</span><span class="p">)</span>
<span class="n">y_test</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SPLIT_ROOT</span> <span class="o">/</span> <span class="s2">&quot;y_test.npy&quot;</span><span class="p">)</span>

<span class="c1"># 3. Balance the training set</span>
<span class="n">idx_inactives</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">idx_actives</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">num_actives</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx_actives</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">idx_inactives_downsampled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
    <span class="n">idx_inactives</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="n">num_actives</span><span class="p">,</span>
    <span class="n">replace</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">X_train_bal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">idx_inactives_downsampled</span><span class="p">],</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">idx_actives</span><span class="p">]</span>
<span class="p">))</span>

<span class="n">y_train_bal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span>
    <span class="n">y_train</span><span class="p">[</span><span class="n">idx_inactives_downsampled</span><span class="p">],</span>
    <span class="n">y_train</span><span class="p">[</span><span class="n">idx_actives</span><span class="p">]</span>
<span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_train_bal</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train_bal</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># 4 Fit model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_bal</span><span class="p">,</span> <span class="n">y_train_bal</span><span class="p">)</span>

<span class="c1"># 5. Scores</span>
<span class="n">y_score_test</span>  <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">y_score_train</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_bal</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1">#6. Compute ROC-AUC (train and test)</span>
<span class="n">auc_test</span>  <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score_test</span><span class="p">)</span>
<span class="n">auc_train</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train_bal</span><span class="p">,</span> <span class="n">y_score_train</span><span class="p">)</span>

<span class="n">fpr_test</span><span class="p">,</span> <span class="n">tpr_test</span><span class="p">,</span> <span class="n">thresholds_test</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score_test</span><span class="p">)</span>
<span class="n">fpr_train</span><span class="p">,</span> <span class="n">tpr_train</span><span class="p">,</span> <span class="n">thresholds_train</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train_bal</span><span class="p">,</span> <span class="n">y_score_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ROC curve arrays created:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test:&quot;</span><span class="p">,</span> <span class="n">fpr_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tpr_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">thresholds_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train:&quot;</span><span class="p">,</span> <span class="n">fpr_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tpr_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">thresholds_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Plot ROC curves</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_test</span><span class="p">,</span>  <span class="n">tpr_test</span><span class="p">,</span>  <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Test ROC (AUC = </span><span class="si">{</span><span class="n">auc_test</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_train</span><span class="p">,</span> <span class="n">tpr_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Train ROC (AUC = </span><span class="si">{</span><span class="n">auc_train</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]:</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds_test</span> <span class="o">-</span> <span class="n">t</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;threshold=</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="p">(</span><span class="n">fpr_test</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">tpr_test</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span>
        <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
        <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
        <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span>
    <span class="p">)</span>


<span class="c1"># Reference line: random classifier</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random (AUC = 0.5)&quot;</span><span class="p">)</span>

<span class="c1"># Labels and title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate (1 − Specificity)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate (Sensitivity)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC Curve: BernoulliNB with MACCS Fingerprints&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1338, 162) (1338,)
ROC curve arrays created:
Test: (144,) (144,) (144,)
Train: (587,) (587,) (587,)
</pre></div>
</div>
<img alt="../../../_images/40144cee8f5685a7c3cd611de882b9591098c9011a3513dc214ae288a6ab260f.png" src="../../../_images/40144cee8f5685a7c3cd611de882b9591098c9011a3513dc214ae288a6ab260f.png" />
</div>
</div>
<p>The ROC curve provides a compact visual summary of how a classifier behaves as its decision threshold is varied. Each point on the curve represents a different trade-off between correctly identifying active compounds (true positives) and incorrectly flagging inactive compounds (false positives). A curve that rises steeply toward the upper-left corner indicates that the model identifies a large fraction of true actives while introducing relatively few false positives at early thresholds. This is the ideal behavior in many screening contexts, where missing active compounds is costly but excessive false positives are also undesirable. In contrast, a curve that closely follows the diagonal line from the bottom-left to the top-right indicates a model with little discriminatory power: true positives and false positives increase at similar rates, as would be expected from random guessing.</p>
<div class="alert alert-block alert-info">
<strong>Deeper Dive: How Thresholds Generate an ROC Curve</strong>
<p><strong>Discussion question:</strong><br>
If the decision threshold is just a single number, how can a single model produce an entire ROC curve?</p>
<div class="alert alert-block alert-success">
<details>
  <summary>Explanation</summary>
  <p>An ROC curve is generated by <em>systematically varying the decision threshold</em> applied to the model’s probability scores.</p>
  <p>Once a model is trained, each compound receives a fixed probability score (for example, <code>P(active)</code>). These scores can be sorted from highest to lowest, creating a ranked list of compounds.</p>
  <p>Starting with a very high threshold (so that no compounds are predicted active), the threshold is gradually lowered. Each time the threshold passes the score of a compound, that compound changes from predicted inactive to predicted active. This change updates the confusion matrix and produces a new pair of values:</p>
  <ul>
    <li><strong>True Positive Rate (TPR):</strong> fraction of true actives correctly identified</li>
    <li><strong>False Positive Rate (FPR):</strong> fraction of true inactives incorrectly flagged</li>
  </ul>
  <p>Each threshold that changes the predictions produces a single point on the ROC curve. Many numerical threshold values may produce the <em>same</em> confusion matrix if no compound scores fall between them, which is why threshold is best thought of as a <em>control parameter</em>, not an axis variable.</p>
  <p>The ROC curve therefore shows how the balance between true positives and false positives evolves as the decision threshold is swept from conservative to permissive.</p>
</details>
</div>
</div>
</section>
<section id="auc-summarizing-roc-behavior">
<h2>4.3 AUC: Summarizing ROC Behavior<a class="headerlink" href="#auc-summarizing-roc-behavior" title="Link to this heading">#</a></h2>
<p>The ROC curve provides a rich visual summary of how a classifier behaves as the decision threshold is varied. However, comparing ROC curves by eye can be difficult, especially when multiple models or datasets are involved. The Area Under the Curve (AUC) provides a way to condense the information contained in the ROC curve into a single number that summarizes overall model performance.</p>
<p>Geometrically, AUC is exactly what its name suggests: the area under the ROC curve, bounded by the axes. Because both the false positive rate and true positive rate range from 0 to 1, the maximum possible area is 1.0. A model whose ROC curve lies close to the upper-left corner of the plot will have a large area under the curve, while a model whose ROC curve follows the diagonal line of random guessing will have an area close to 0.5.</p>
<p>Importantly, AUC does not correspond to performance at any single decision threshold. Instead, it summarizes how the model behaves across all thresholds. Models with high AUC values tend to achieve high true positive rates while keeping false positive rates low over a wide range of thresholds. Models with AUC values near 0.5 show little ability to distinguish actives from inactives, regardless of how the threshold is chosen.</p>
<p>From a conceptual perspective, AUC can also be understood as a ranking metric. It represents the probability that a randomly chosen active compound receives a higher predicted score than a randomly chosen inactive compound. In this interpretation, AUC measures how well the model orders compounds by their likelihood of activity, independent of any particular cutoff or decision rule.</p>
<p>This ranking-based view explains why AUC is often described as threshold-independent. The threshold is still present implicitly, it is swept across all possible values when the ROC curve is constructed, but no single threshold is privileged. AUC therefore answers a different question than accuracy or sensitivity: does the model meaningfully separate actives from inactives at all?</p>
<p>AUC does not tell us which threshold to use, nor does it encode the costs of false positives and false negatives. Instead, it provides a diagnostic measure of whether the model contains useful discriminatory information. Once that information is established, threshold selection becomes a separate decision-making problem, guided by scientific goals, resource constraints, and tolerance for error.</p>
<div class="alert alert-block alert-info">
<strong>Before Running the next code cell predict if the training set or the test set would have the higher AUC score</strong>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute AUC for train and test sets</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">roc_auc_score</span>

<span class="c1"># AUC values</span>
<span class="n">auc_train</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train_bal</span><span class="p">,</span> <span class="n">y_score_train</span><span class="p">)</span>
<span class="n">auc_test</span>  <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ROC–AUC Summary&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training AUC (balanced): </span><span class="si">{</span><span class="n">auc_train</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test AUC:               </span><span class="si">{</span><span class="n">auc_test</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Interpretation guide:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;AUC ≈ 0.5 → no discrimination (random)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;AUC → 1.0 → strong separation of actives and inactives&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ROC–AUC Summary
----------------
Training AUC (balanced): 0.755
Test AUC:               0.728

Interpretation guide:
AUC ≈ 0.5 → no discrimination (random)
AUC → 1.0 → strong separation of actives and inactives
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-info">
<strong>Looking Ahead: What Does AUC Actually Measure?</strong>
<p><strong>Discussion question:</strong><br>
Two classifiers produce ROC curves that start at (0, 0) and end at (1, 1), as all ROC curves must. One curve rises steeply toward the upper-left corner at low false positive rates, while the other remains closer to the diagonal for much of its length.</p>
<div class="alert alert-block alert-success">
<details>
  <summary>Explanation</summary>
  <p>The Area Under the ROC Curve (AUC) summarizes the model’s performance across <em>all possible decision thresholds</em> into a single number.</p>
  <p>Geometrically, AUC is the total area beneath the ROC curve. Intuitively, it reflects how quickly the curve rises toward the upper-left corner, where true positives are maximized while false positives remain low.</p>
  <p>From a ranking perspective, AUC can be interpreted as the probability that a randomly chosen active compound receives a higher score than a randomly chosen inactive compound.</p>
  <p>AUC does <em>not</em> select a threshold or define a decision rule. Instead, it answers a different question: <em>Does the model meaningfully separate actives from inactives at all?</em> Threshold selection comes later, once this overall separation has been established.</p>
</details>
</div>
</div>
<p>The ROC curves for both the training and test sets lie well above the diagonal reference line, indicating that the model has learned a meaningful ranking signal rather than behaving like a random classifier. The training curve consistently exceeds the test curve, as expected, but the gap between them is modest, suggesting limited overfitting and reasonable generalization. The test-set AUC of approximately 0.72 confirms that active compounds tend to receive higher scores than inactive compounds, even though no single decision threshold has yet been chosen. At the same time, the gradual rise of the curve highlights an inherent trade-off: increasing sensitivity necessarily increases the false positive rate. This reinforces the idea that ROC–AUC evaluates whether useful separation exists at all, while the choice of a specific threshold must be guided by scientific or practical priorities.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="choosing-an-operating-threshold-decision-engineering">
<h1>5. Choosing an Operating Threshold (Decision Engineering)<a class="headerlink" href="#choosing-an-operating-threshold-decision-engineering" title="Link to this heading">#</a></h1>
<p>What principle should we use to choose the optimal theshold to generate the confusion matrix?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="c1"># Run code in section 4 to reload and fit the model</span>
<span class="c1">#5 Predict Hard Labels</span>
<span class="n">y_pred_test</span>  <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_bal</span><span class="p">)</span>

<span class="c1"># Create confusion matrices (train and test)</span>

<span class="n">cm_test</span>  <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="n">cm_train</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train_bal</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)</span>

<span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">TP</span> <span class="o">=</span> <span class="n">cm_test</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">TN_tr</span><span class="p">,</span> <span class="n">FP_tr</span><span class="p">,</span> <span class="n">FN_tr</span><span class="p">,</span> <span class="n">TP_tr</span> <span class="o">=</span> <span class="n">cm_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test confusion matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cm_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Training confusion matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cm_train</span><span class="p">)</span>
<span class="n">FPR_current</span> <span class="o">=</span> <span class="n">FP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span>
<span class="n">TPR_current</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Plot test ROC curve</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">fpr_test</span><span class="p">,</span>
    <span class="n">tpr_test</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Test ROC (AUC = </span><span class="si">{</span><span class="n">auc_test</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span>
<span class="p">)</span>

<span class="c1"># Plot random baseline</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random (AUC = 0.5)&quot;</span>
<span class="p">)</span>

<span class="c1"># Mark current operating point</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">FPR_current</span><span class="p">,</span>
    <span class="n">TPR_current</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
    <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Current operating point (threshold ≈ 0.5)&quot;</span>
<span class="p">)</span>

<span class="c1"># Annotate the point</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
    <span class="s2">&quot;Current threshold&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="n">FPR_current</span><span class="p">,</span> <span class="n">TPR_current</span><span class="p">),</span>
    <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Labels and title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate (1 − Specificity)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate (Sensitivity)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC Curve with Current Operating Point&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># --- Current operating point from test confusion matrix ---</span>

<span class="n">FPR_current</span> <span class="o">=</span> <span class="n">FP</span> <span class="o">/</span> <span class="p">(</span><span class="n">FP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span>
<span class="n">TPR_current</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Current operating point (default threshold ~0.5):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;False Positive Rate (FPR) = </span><span class="si">{</span><span class="n">FPR_current</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True Positive Rate (TPR)  = </span><span class="si">{</span><span class="n">TPR_current</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test confusion matrix:
 [[400 206]
 [ 25  49]]

Training confusion matrix:
 [[457 212]
 [187 482]]
</pre></div>
</div>
<img alt="../../../_images/82d4961cbf75143866ab9a1d5b67dadcfbde39c0253551e9c52d264a0dcfae8a.png" src="../../../_images/82d4961cbf75143866ab9a1d5b67dadcfbde39c0253551e9c52d264a0dcfae8a.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Current operating point (default threshold ~0.5):
False Positive Rate (FPR) = 0.3399
True Positive Rate (TPR)  = 0.6622
</pre></div>
</div>
</div>
</div>
<section id="locating-the-current-operating-point">
<h2>5.1 Locating the Current Operating Point<a class="headerlink" href="#locating-the-current-operating-point" title="Link to this heading">#</a></h2>
<p>The red point shown on the ROC curve represents the current operating point of the classifier, produced by the default decision rule used by .predict() (approximately a probability threshold of 0.5). This point is computed directly from the confusion matrix, not from the ROC curve itself.</p>
<p>Importantly, this operating point is not guaranteed to correspond exactly to a point on the ROC curve. The ROC curve is constructed by sweeping through data-derived probability thresholds, whereas the default threshold is a fixed parameter of the classifier. As a result, the default threshold usually falls between two ROC thresholds rather than exactly on one.</p>
<p>To relate the default classifier to the ROC curve, we therefore identify the nearest ROC point in (FPR, TPR) space. This allows us to locate where the default decision rule lies relative to all possible threshold choices, even though it is not itself a ROC threshold. This distinction matters because choosing an operating threshold is a decision problem, not a plotting artifact. The ROC curve shows what is possible; selecting a threshold determines what the model actually does. We now turn to principled ways of making that choice.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute distance between current operating point and each ROC point</span>
<span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
    <span class="p">(</span><span class="n">fpr_test</span> <span class="o">-</span> <span class="n">FPR_current</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span>
    <span class="p">(</span><span class="n">tpr_test</span> <span class="o">-</span> <span class="n">TPR_current</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="p">)</span>

<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Closest ROC point index:&quot;</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Threshold at this point = </span><span class="si">{</span><span class="n">thresholds_test</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FPR at this point       = </span><span class="si">{</span><span class="n">fpr_test</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TPR at this point       = </span><span class="si">{</span><span class="n">tpr_test</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Closest ROC point index: 74
Threshold at this point = 0.4585
FPR at this point       = 0.3515
TPR at this point       = 0.6622
</pre></div>
</div>
</div>
</div>
<p>Note: The decision threshold is not associated with either ROC axis. It is a model parameter, not a plotted variable. The default threshold (≈ 0.5) produces an operating point at FPR = 0.3399 and TPR = 0.6622, but this point is not itself a ROC data point. It lies between ROC thresholds derived from the model’s predicted probabilities.</p>
</section>
<section id="choosing-an-operating-threshold-youden-s-j-statistic">
<h2>5.2 Choosing an Operating Threshold: Youden’s J statistic<a class="headerlink" href="#choosing-an-operating-threshold-youden-s-j-statistic" title="Link to this heading">#</a></h2>
<p>What principle should we use to choose the optimal theshold to generate the confusion matrix?</p>
<p>At what threshold is a model simultaneously good at finding actives and rejecting inactives? One answer is given by Youden’s J statistic, which identifies the point on the ROC curve that is farthest vertically from the diagonal (random classification):
$<span class="math notranslate nohighlight">\( J = TPR-FPR \)</span>$</p>
<ul class="simple">
<li><p>J=0  random performance</p></li>
<li><p>J=1 perfect classification</p></li>
<li><p>At each threshold, J is the vertical distance between the ROC curve and the diagonal</p></li>
<li><p>Maximizing J is equivalent to maximizing TPR relative to FPR</p></li>
</ul>
<p>Other threshold-selection criteria exist, including distance-based, cost-based, and policy-driven approaches. In practice, threshold selection is a form of decision engineering, not model evaluation.</p>
<p>From this point forward, we explicitly distinguish between confusion matrices computed at different decision thresholds. When comparing thresholds, each operating point must be evaluated using its own confusion matrix, and variables are named to reflect the decision rule used to generate them</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 10 Youden&#39;s J – choose threshold (training set)</span>

<span class="n">youden_J_train</span> <span class="o">=</span> <span class="n">tpr_train</span> <span class="o">-</span> <span class="n">fpr_train</span>
<span class="n">idx_J</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">youden_J_train</span><span class="p">)</span>

<span class="n">youden_threshold</span> <span class="o">=</span> <span class="n">thresholds_train</span><span class="p">[</span><span class="n">idx_J</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Youden-optimal threshold (from training data):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Threshold = </span><span class="si">{</span><span class="n">youden_threshold</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TPR       = </span><span class="si">{</span><span class="n">tpr_train</span><span class="p">[</span><span class="n">idx_J</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FPR       = </span><span class="si">{</span><span class="n">fpr_train</span><span class="p">[</span><span class="n">idx_J</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Youden J  = </span><span class="si">{</span><span class="n">youden_J_train</span><span class="p">[</span><span class="n">idx_J</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Youden-optimal threshold (from training data):
Threshold = 0.0908
TPR       = 0.8430
FPR       = 0.4350
Youden J  = 0.4081
</pre></div>
</div>
</div>
</div>
<p>Because threshold selection is a tuning step, we determine the Youden-optimal threshold using the training data and then apply it to the test set for evaluation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 11 Apply Youden&#39;s threshold (new predictions)</span>
<span class="n">y_test_pred_youden</span>  <span class="o">=</span> <span class="p">(</span><span class="n">y_score_test</span>  <span class="o">&gt;=</span> <span class="n">youden_threshold</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">y_pred_train_youden</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_score_train</span> <span class="o">&gt;=</span> <span class="n">youden_threshold</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># 12. Confusion matrices (youden-optimal)</span>
<span class="n">cm_test_youden</span>  <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred_youden</span><span class="p">)</span>
<span class="n">cm_train_youden</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train_bal</span><span class="p">,</span> <span class="n">y_pred_train_youden</span><span class="p">)</span>

<span class="n">TN_y</span><span class="p">,</span> <span class="n">FP_y</span><span class="p">,</span> <span class="n">FN_y</span><span class="p">,</span> <span class="n">TP_y</span> <span class="o">=</span> <span class="n">cm_test_youden</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">TN_tr_y</span><span class="p">,</span> <span class="n">FP_tr_y</span><span class="p">,</span> <span class="n">FN_tr_y</span><span class="p">,</span> <span class="n">TP_tr_y</span> <span class="o">=</span> <span class="n">cm_train_youden</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test confusion matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cm_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test confusion matrix (Youden-optimal):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cm_test_youden</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Training confusion matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cm_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Training confusion matrix (Youden-optimal):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cm_train_youden</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test confusion matrix:
 [[400 206]
 [ 25  49]]
Test confusion matrix (Youden-optimal):
 [[325 281]
 [ 13  61]]

Training confusion matrix:
 [[457 212]
 [187 482]]

Training confusion matrix (Youden-optimal):
 [[378 291]
 [105 564]]
</pre></div>
</div>
</div>
</div>
<p>The confusion matrices below show the impact of replacing the default decision threshold with the Youden-optimal threshold learned from the training data.</p>
<p>At the default threshold, the classifier is relatively conservative: it produces fewer false positives but also misses a substantial number of actives. When the threshold is shifted to the Youden-optimal value, the classifier becomes more permissive, reflecting an explicit trade-off between sensitivity and specificity.</p>
<p>On the test set, applying the Youden-optimal threshold:</p>
<p>Increases true positives (49 → 61), improving the model’s ability to identify actives</p>
<p>Decreases false negatives (25 → 13), reducing missed actives</p>
<p>Increases false positives (206 → 281), accepting more inactives as a consequence</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#  Predict probability scores</span>
<span class="n">y_score_test</span>  <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">y_score_train</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_bal</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># 9. ROC curve and AUC (test set)</span>
<span class="n">fpr_test</span><span class="p">,</span> <span class="n">tpr_test</span><span class="p">,</span> <span class="n">thresholds_test</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score_test</span><span class="p">)</span>
<span class="n">auc_test</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test ROC–AUC = </span><span class="si">{</span><span class="n">auc_test</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test ROC–AUC = 0.7279
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#### Compare Default and Youden values</span>
<span class="c1"># Compute operating point for default threshold</span>
<span class="n">cm_default</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="n">TN_d</span><span class="p">,</span> <span class="n">FP_d</span><span class="p">,</span> <span class="n">FN_d</span><span class="p">,</span> <span class="n">TP_d</span> <span class="o">=</span> <span class="n">cm_default</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="n">FPR_default</span> <span class="o">=</span> <span class="n">FP_d</span> <span class="o">/</span> <span class="p">(</span><span class="n">FP_d</span> <span class="o">+</span> <span class="n">TN_d</span><span class="p">)</span>
<span class="n">TPR_default</span> <span class="o">=</span> <span class="n">TP_d</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP_d</span> <span class="o">+</span> <span class="n">FN_d</span><span class="p">)</span>

<span class="c1"># Compute operating point for Youden-optimal threshold</span>
<span class="n">cm_youden</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred_youden</span><span class="p">)</span>
<span class="n">TN_y</span><span class="p">,</span> <span class="n">FP_y</span><span class="p">,</span> <span class="n">FN_y</span><span class="p">,</span> <span class="n">TP_y</span> <span class="o">=</span> <span class="n">cm_youden</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="n">FPR_youden</span> <span class="o">=</span> <span class="n">FP_y</span> <span class="o">/</span> <span class="p">(</span><span class="n">FP_y</span> <span class="o">+</span> <span class="n">TN_y</span><span class="p">)</span>
<span class="n">TPR_youden</span> <span class="o">=</span> <span class="n">TP_y</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP_y</span> <span class="o">+</span> <span class="n">FN_y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Default operating point:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FPR = </span><span class="si">{</span><span class="n">FPR_default</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, TPR = </span><span class="si">{</span><span class="n">TPR_default</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Youden-optimal operating point:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FPR = </span><span class="si">{</span><span class="n">FPR_youden</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, TPR = </span><span class="si">{</span><span class="n">TPR_youden</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># ROC curve</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">fpr_test</span><span class="p">,</span>
    <span class="n">tpr_test</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;ROC Curve (AUC = </span><span class="si">{</span><span class="n">auc_test</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span>
<span class="p">)</span>

<span class="c1"># Random classifier reference</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random classifier (AUC = 0.5)&quot;</span>
<span class="p">)</span>

<span class="c1"># Default threshold operating point</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">FPR_default</span><span class="p">,</span>
    <span class="n">TPR_default</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
    <span class="n">s</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span>
    <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Default threshold (~0.5)&quot;</span>
<span class="p">)</span>

<span class="c1"># Youden-optimal operating point</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">FPR_youden</span><span class="p">,</span>
    <span class="n">TPR_youden</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">,</span>
    <span class="n">s</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span>
    <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Youden-optimal threshold&quot;</span>
<span class="p">)</span>

<span class="c1"># Annotate points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
    <span class="s2">&quot;Default&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="n">FPR_default</span><span class="p">,</span> <span class="n">TPR_default</span><span class="p">),</span>
    <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
    <span class="s2">&quot;Youden&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="n">FPR_youden</span><span class="p">,</span> <span class="n">TPR_youden</span><span class="p">),</span>
    <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Labels and title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate (1 − Specificity)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate (Sensitivity)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC Curve with Default and Youden-Optimal Operating Points&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Default operating point:
FPR = 0.3399, TPR = 0.6622

Youden-optimal operating point:
FPR = 0.4637, TPR = 0.8243
</pre></div>
</div>
<img alt="../../../_images/4e683cfaa526179d18baeeca126a9721d848df778da431a3e92a6d89d42ea842.png" src="../../../_images/4e683cfaa526179d18baeeca126a9721d848df778da431a3e92a6d89d42ea842.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># ---------- Default threshold metrics ----------</span>
<span class="n">acc_d</span>  <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="n">prec_d</span> <span class="o">=</span> <span class="n">TP_d</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP_d</span> <span class="o">+</span> <span class="n">FP_d</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">TP_d</span> <span class="o">+</span> <span class="n">FP_d</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>
<span class="n">sens_d</span> <span class="o">=</span> <span class="n">TP_d</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP_d</span> <span class="o">+</span> <span class="n">FN_d</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">TP_d</span> <span class="o">+</span> <span class="n">FN_d</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>
<span class="n">spec_d</span> <span class="o">=</span> <span class="n">TN_d</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN_d</span> <span class="o">+</span> <span class="n">FP_d</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">TN_d</span> <span class="o">+</span> <span class="n">FP_d</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>
<span class="n">bacc_d</span> <span class="o">=</span> <span class="p">(</span><span class="n">sens_d</span> <span class="o">+</span> <span class="n">spec_d</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">f1_d</span>   <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">prec_d</span> <span class="o">*</span> <span class="n">sens_d</span> <span class="o">/</span> <span class="p">(</span><span class="n">prec_d</span> <span class="o">+</span> <span class="n">sens_d</span><span class="p">))</span> <span class="k">if</span> <span class="p">(</span><span class="n">prec_d</span> <span class="o">+</span> <span class="n">sens_d</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>

<span class="c1"># ---------- Youden-optimal metrics ----------</span>
<span class="n">acc_y</span>  <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred_youden</span><span class="p">)</span>
<span class="n">prec_y</span> <span class="o">=</span> <span class="n">TP_y</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP_y</span> <span class="o">+</span> <span class="n">FP_y</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">TP_y</span> <span class="o">+</span> <span class="n">FP_y</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>
<span class="n">sens_y</span> <span class="o">=</span> <span class="n">TP_y</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP_y</span> <span class="o">+</span> <span class="n">FN_y</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">TP_y</span> <span class="o">+</span> <span class="n">FN_y</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>
<span class="n">spec_y</span> <span class="o">=</span> <span class="n">TN_y</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN_y</span> <span class="o">+</span> <span class="n">FP_y</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">TN_y</span> <span class="o">+</span> <span class="n">FP_y</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>
<span class="n">bacc_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">sens_y</span> <span class="o">+</span> <span class="n">spec_y</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">f1_y</span>   <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">prec_y</span> <span class="o">*</span> <span class="n">sens_y</span> <span class="o">/</span> <span class="p">(</span><span class="n">prec_y</span> <span class="o">+</span> <span class="n">sens_y</span><span class="p">))</span> <span class="k">if</span> <span class="p">(</span><span class="n">prec_y</span> <span class="o">+</span> <span class="n">sens_y</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TEST SET PERFORMANCE COMPARISON</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Default threshold (~0.5)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy          = </span><span class="si">{</span><span class="n">acc_d</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision         = </span><span class="si">{</span><span class="n">prec_d</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity       = </span><span class="si">{</span><span class="n">sens_d</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Specificity       = </span><span class="si">{</span><span class="n">spec_d</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Balanced Accuracy = </span><span class="si">{</span><span class="n">bacc_d</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score          = </span><span class="si">{</span><span class="n">f1_d</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Youden-optimal threshold&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy          = </span><span class="si">{</span><span class="n">acc_y</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision         = </span><span class="si">{</span><span class="n">prec_y</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity       = </span><span class="si">{</span><span class="n">sens_y</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Specificity       = </span><span class="si">{</span><span class="n">spec_y</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Balanced Accuracy = </span><span class="si">{</span><span class="n">bacc_y</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score          = </span><span class="si">{</span><span class="n">f1_y</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TEST SET PERFORMANCE COMPARISON

Default threshold (~0.5)
Accuracy          = 0.6603
Precision         = 0.1922
Sensitivity       = 0.6622
Specificity       = 0.6601
Balanced Accuracy = 0.6611
F1 Score          = 0.2979

Youden-optimal threshold
Accuracy          = 0.5676
Precision         = 0.1784
Sensitivity       = 0.8243
Specificity       = 0.5363
Balanced Accuracy = 0.6803
F1 Score          = 0.2933
</pre></div>
</div>
</div>
</div>
<p>The ROC curve summarizes all possible operating points for the classifier. The default and Youden-optimal thresholds correspond to specific locations on this curve, illustrating how threshold selection shifts the balance between sensitivity and specificity without changing the underlying model.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>Default Threshold</p></th>
<th class="head"><p>Youden-Optimal Threshold</p></th>
<th class="head"><p>Interpretation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Accuracy</strong></p></td>
<td><p><strong>0.6603</strong></p></td>
<td><p>0.5676</p></td>
<td><p>Accuracy decreases at the Youden-optimal threshold because more inactive compounds are intentionally classified as active. In imbalanced datasets, accuracy can be misleading.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Precision</strong></p></td>
<td><p><strong>0.1922</strong></p></td>
<td><p>0.1784</p></td>
<td><p>Precision decreases slightly as sensitivity increases. This reflects the cost of accepting more false positives to capture additional actives.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Sensitivity (Recall)</strong></p></td>
<td><p>0.6622</p></td>
<td><p><strong>0.8243</strong></p></td>
<td><p>Sensitivity increases substantially at the Youden-optimal threshold, indicating that fewer active compounds are missed.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Specificity</strong></p></td>
<td><p><strong>0.6601</strong></p></td>
<td><p>0.5363</p></td>
<td><p>Specificity decreases, as more inactive compounds are incorrectly classified as active.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Balanced Accuracy</strong></p></td>
<td><p>0.6611</p></td>
<td><p><strong>0.6803</strong></p></td>
<td><p>Balanced accuracy improves, showing better overall separation between actives and inactives when class imbalance is taken into account.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>F1 Score</strong></p></td>
<td><p><strong>0.2979</strong></p></td>
<td><p>0.2933</p></td>
<td><p>The F1 score remains similar, illustrating that improvements in recall are largely offset by reduced precision.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>                           |
</pre></div>
</div>
<p>Changing the decision threshold does not improve all metrics simultaneously. The Youden-optimal threshold favors finding actives, even at the cost of more false positives. This trade-off may be desirable in screening applications but must be evaluated in the context of experimental goals and resource constraints.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">cm_default</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">TN_d</span><span class="p">,</span> <span class="n">FP_d</span><span class="p">],</span>
                       <span class="p">[</span><span class="n">FN_d</span><span class="p">,</span> <span class="n">TP_d</span><span class="p">]])</span>

<span class="n">cm_youden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">TN_y</span><span class="p">,</span> <span class="n">FP_y</span><span class="p">],</span>
                      <span class="p">[</span><span class="n">FN_y</span><span class="p">,</span> <span class="n">TP_y</span><span class="p">]])</span>

<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Default Threshold&quot;</span><span class="p">,</span> <span class="s2">&quot;Youden-Optimal Threshold&quot;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">cm</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="p">[</span><span class="n">cm_default</span><span class="p">,</span> <span class="n">cm_youden</span><span class="p">],</span> <span class="n">titles</span><span class="p">):</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">)</span>

    <span class="c1"># Annotate cells with counts</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span>
                    <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;Predicted Inactive&quot;</span><span class="p">,</span> <span class="s2">&quot;Predicted Active&quot;</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s2">&quot;True Inactive&quot;</span><span class="p">,</span> <span class="s2">&quot;True Active&quot;</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/658c458895a1a6b9144ccd34c651f510ca1668bb279b27446779acd8c9812527.png" src="../../../_images/658c458895a1a6b9144ccd34c651f510ca1668bb279b27446779acd8c9812527.png" />
</div>
</div>
<p>The two confusion matrices illustrate how changing the decision threshold alters the classifier’s operating behavior without changing the underlying model. At the default threshold, the classifier is more conservative: it correctly identifies 400 inactive compounds and 49 active compounds, but misses 25 actives and incorrectly labels 206 inactives as active. When the Youden-optimal threshold is applied, the classifier becomes more permissive. The number of correctly identified actives increases (49 → 61), and missed actives decrease substantially (25 → 13), indicating improved sensitivity. However, this gain comes at the cost of reduced specificity: more inactive compounds are incorrectly classified as active (206 → 281), and fewer inactives are correctly rejected (400 → 325). This comparison makes explicit the trade off introduced by threshold selection, improving the ability to find actives necessarily increases false positives, and reinforces that different thresholds correspond to different operational priorities rather than “better” or “worse” models.</p>
<p><strong>Comparing Training and Test Performance at the Youden-Optimal Threshold</strong></p>
<p>Evaluating the classifier at the Youden-optimal threshold highlights how model performance depends not only on the learned representation, but also on the decision rule used to translate probabilities into classifications. At this operating point, balanced accuracy improves relative to the default threshold on the test set (0.680 vs. 0.661), indicating better overall separation between active and inactive compounds when class imbalance is taken into account. This improvement is driven by a substantial increase in sensitivity, with more active compounds correctly identified, accompanied by a corresponding decrease in specificity as additional inactives are accepted.</p>
<p>Comparing training and test behavior at the Youden-optimal threshold shows that this trade-off is preserved across datasets: in both cases, sensitivity increases while specificity decreases relative to the default operating point. This consistency suggests that the model’s underlying ranking of compounds generalizes reasonably well to unseen data, even though individual performance metrics shift with dataset composition.</p>
<p>Importantly, metrics such as accuracy, precision, and F1 score change in different, and sometimes counterintuitive, ways as the threshold is adjusted. Precision in particular remains low on the test set due to extreme class imbalance, despite improvements in sensitivity and balanced accuracy. This reinforces a central lesson of this module: no single metric fully captures model performance, and threshold selection reflects experimental priorities rather than an objective notion of correctness.</p>
<p>Taken together, these results emphasize that model evaluation does not end with training. A trained classifier defines a continuum of possible operating behaviors, and selecting a threshold is a form of decision engineering that must be guided by the goals, constraints, and costs of the scientific application</p>
<p>Comparing confusion matrices at different thresholds shows that threshold selection controls the balance of false positives and false negatives without altering the learned model, making ROC-guided decisions an essential step in supervised learning.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="homework">
<h1>6. Homework<a class="headerlink" href="#homework" title="Link to this heading">#</a></h1>
<p>In section 3.2 Recover CIDs of compounds you created a dataframe (df_test_proba) that contained 680 PubChem CIDs and their predicted activities.  You will use that dataset as the starting point for this assignment.</p>
<section id="part-1-threshold-exploration">
<h2>Part 1: Threshold Exploration<a class="headerlink" href="#part-1-threshold-exploration" title="Link to this heading">#</a></h2>
<p>Create a Pandas DataFrame with</p>
<ul class="simple">
<li><p>Pubchem CID</p></li>
<li><p>y_true (actual active/inactive value)</p></li>
<li><p>p_active from .predict_proba() - the probablity score ranking</p></li>
</ul>
<p>Populate this data frame with 30 compounds roughly evenly spaced</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_sorted</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;p_active&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_sorted</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df_even30</span> <span class="o">=</span> <span class="n">df_sorted</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple">
<li><p>Add Threshold colums for the following values (0.0, 0.33, 0.67 and 1.0)</p></li>
<li><p>In each column use the threshold to indicate of a chemical is active or inactive.</p></li>
</ol>
<blockquote>
<div><p>The following code creates a boolean value for each threshold and then converts it to an integer</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#thresholds = [0.0, 0.33, 0.67, 1.0]</span>

<span class="n">pred_col</span> <span class="o">=</span> <span class="s2">&quot;pred_t0.33&quot;</span>

<span class="n">TN</span> <span class="o">=</span> <span class="p">((</span><span class="n">df_even30</span><span class="p">[</span><span class="n">pred_col</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_even30</span><span class="p">[</span><span class="s2">&quot;y_true&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">FP</span> <span class="o">=</span> <span class="p">((</span><span class="n">df_even30</span><span class="p">[</span><span class="n">pred_col</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_even30</span><span class="p">[</span><span class="s2">&quot;y_true&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">FN</span> <span class="o">=</span> <span class="p">((</span><span class="n">df_even30</span><span class="p">[</span><span class="n">pred_col</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_even30</span><span class="p">[</span><span class="s2">&quot;y_true&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">TP</span> <span class="o">=</span> <span class="p">((</span><span class="n">df_even30</span><span class="p">[</span><span class="n">pred_col</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_even30</span><span class="p">[</span><span class="s2">&quot;y_true&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="n">cm</span> <span class="o">=</span> <span class="p">[[</span><span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">],</span>
      <span class="p">[</span><span class="n">FN</span><span class="p">,</span> <span class="n">TP</span><span class="p">]]</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Using your dataframe create a confusion matrix for the 4 thresholds (two are trivial). That is:</p>
<p>-count TN, FN, TP and FP, and arrange them into a matrix using matplotlib or seaborn</p>
</section>
<section id="part-2-analysis-of-top-predictions">
<h2>Part 2: Analysis of Top Predictions<a class="headerlink" href="#part-2-analysis-of-top-predictions" title="Link to this heading">#</a></h2>
<p>The goal here is to look for similarity of the top 30 compounds and see if there is a chemical correlation to activity.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_top30</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df</span>
    <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;p_active&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
    <span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Using this subset of compounds, carry out the following steps:</p>
<ol class="arabic simple">
<li><p>Convert the PubChem CIDs to RDKit molecule objects and display the molecular structures.</p></li>
<li><p>Using the chosen decision threshold, identify each compound as a true positive (TP) or false positive (FP).</p></li>
<li><p>Reorder the DataFrame so that all true positives appear first, followed by all false positives.</p></li>
<li><p>Regenerate MACCS fingerprints for these compounds as RDKit explicit bit vectors.</p></li>
<li><p>Compute pairwise Tanimoto similarity scores between all compounds.</p></li>
<li><p>Visualize the resulting similarity matrix as a heat map, ordered with true positives first and false positives last.<br />
Note: The similarity matrix will be symmetric, and the diagonal elements will always have a value of 1.0.</p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "datachem"
        },
        kernelOptions: {
            name: "datachem",
            path: "./content/modules/10_SupervisedML"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'datachem'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="10_2_NB_model_construction_workflow.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">10.2: Naive Bayes and Model Construction</p>
      </div>
    </a>
    <a class="right-next"
       href="../../appendices/App_1/README.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Appendix 1.1: Getting Set Up</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">10.3: Evaluating and Interpreting Models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-evaluation-means">What Evaluation Means?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstructing-the-model-reproducibility-checkpoint">1. Reconstructing the Model (Reproducibility Checkpoint)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regenerate-the-model">1.1 Regenerate the Model</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-based-evaluation-predict">2. Classification Based Evaluation (<code class="docutils literal notranslate"><span class="pre">.predict()</span></code>)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#confusion-matrix-based-evaluation-metrics">2.1 Confusion Matrix Based Evaluation Metrics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-confusion-matrix-metrics">2.2 Table of Confusion Matrix Metrics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">2.3. Confusion Matrix Based Evaluation Metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy">2.3.1 Accuracy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#precision">2.3.2 Precision</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sensitivity-recall-true-positive-rate">2.3.3 Sensitivity (Recall / True Positive Rate)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specificity-true-negative-rate">2.3.4 Specificity (True Negative Rate)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#balanced-accuracy">2.3.5 Balanced Accuracy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#f1-score">2.3.6 F1 Score</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-differences-between-training-and-test-performance">2.4 Interpreting Differences Between Training and Test Performance</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#under-the-hood-confusion-matrices-thresholds-and-probability-scores">3. Under the Hood: Confusion Matrices, Thresholds and Probability Scores</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-evaluation-predict-proba">3.1 Probabilistic Evaluation (<code class="docutils literal notranslate"><span class="pre">.predict_proba</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recover-cids-of-compounds">3.2 Recover CIDs of compounds</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-auc-threshold-independent-performance">4. ROC/AUC: Threshold-Independent Performance</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-confusion-matrices-to-rates">4.1 From confusion matrices to rates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-curves-and-decision-thresholds">4.2 ROC Curves and Decision Thresholds</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#auc-summarizing-roc-behavior">4.3 AUC: Summarizing ROC Behavior</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#choosing-an-operating-threshold-decision-engineering">5. Choosing an Operating Threshold (Decision Engineering)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#locating-the-current-operating-point">5.1 Locating the Current Operating Point</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#choosing-an-operating-threshold-youden-s-j-statistic">5.2 Choosing an Operating Threshold: Youden’s J statistic</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#homework">6. Homework</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-threshold-exploration">Part 1: Threshold Exploration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-analysis-of-top-predictions">Part 2: Analysis of Top Predictions</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Robert Belford
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright CC 4.0 2026 Robert Belford, additional info on each notebook.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <script async src="https://hypothes.is/embed.js"></script>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>